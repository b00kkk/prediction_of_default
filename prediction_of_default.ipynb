{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "BeCUXFbKfZEx"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "딥러닝"
      ],
      "metadata": {
        "id": "NSgj0RlNhZU8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# ✅ 데이터 로드\n",
        "train_path = \"train.csv\"\n",
        "test_path = \"test.csv\"\n",
        "\n",
        "train_df = pd.read_csv(train_path)\n",
        "test_df = pd.read_csv(test_path)\n",
        "\n",
        "# ✅ 목표 변수 분리\n",
        "X = train_df.drop(columns=[\"UID\", \"채무 불이행 여부\"])\n",
        "y = train_df[\"채무 불이행 여부\"]\n",
        "\n",
        "# 테스트 데이터 UID 저장\n",
        "test_UID = test_df.pop(\"UID\")\n",
        "X_test = test_df\n",
        "\n",
        "# ✅ 범주형 변수 인코딩\n",
        "categorical_cols = [\"주거 형태\", \"대출 목적\", \"대출 상환 기간\"]\n",
        "label_col = \"현재 직장 근속 연수\"\n",
        "\n",
        "# OneHot Encoding (주거 형태, 대출 목적, 대출 상환 기간)\n",
        "encoder = OneHotEncoder(sparse_output=False, drop=\"first\")\n",
        "X_encoded = encoder.fit_transform(X[categorical_cols])\n",
        "X_test_encoded = encoder.transform(X_test[categorical_cols])\n",
        "encoded_cols = encoder.get_feature_names_out(categorical_cols)\n",
        "\n",
        "X_encoded_df = pd.DataFrame(X_encoded, columns=encoded_cols, index=X.index)\n",
        "X_test_encoded_df = pd.DataFrame(X_test_encoded, columns=encoded_cols, index=X_test.index)\n",
        "\n",
        "# Label Encoding (현재 직장 근속 연수)\n",
        "label_encoder = LabelEncoder()\n",
        "X[label_col] = label_encoder.fit_transform(X[label_col])\n",
        "X_test[label_col] = label_encoder.transform(X_test[label_col])\n",
        "\n",
        "# ✅ 기존 데이터에서 범주형 변수 제거 후 결합\n",
        "X = X.drop(columns=categorical_cols).reset_index(drop=True)\n",
        "X_test = X_test.drop(columns=categorical_cols).reset_index(drop=True)\n",
        "\n",
        "X = pd.concat([X, X_encoded_df], axis=1)\n",
        "X_test = pd.concat([X_test, X_test_encoded_df], axis=1)\n",
        "\n",
        "# 로그 변환\n",
        "log_columns = [\"현재 미상환 신용액\", \"월 상환 부채액\", \"현재 대출 잔액\"]\n",
        "for col in log_columns:\n",
        "    X[col] = np.log1p(X[col])\n",
        "    X_test[col] = np.log1p(X_test[col])\n",
        "\n",
        "# ✅ 데이터 스케일링\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# ✅ 훈련 데이터 분할\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# ✅ MLP (Multi-Layer Perceptron) 모델 설계\n",
        "def build_model(input_dim):\n",
        "    model = keras.Sequential([\n",
        "        layers.Dense(128, activation=\"relu\", input_shape=(input_dim,)),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dropout(0.3),\n",
        "\n",
        "        layers.Dense(64, activation=\"relu\"),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dropout(0.3),\n",
        "\n",
        "        layers.Dense(32, activation=\"relu\"),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dropout(0.3),\n",
        "\n",
        "        layers.Dense(1, activation=\"sigmoid\")  # Binary Classification\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "                  loss=\"binary_crossentropy\",\n",
        "                  metrics=[keras.metrics.AUC()])\n",
        "\n",
        "    return model\n",
        "\n",
        "# ✅ 모델 생성\n",
        "model = build_model(X_train.shape[1])\n",
        "\n",
        "# ✅ 모델 학습\n",
        "early_stopping = keras.callbacks.EarlyStopping(monitor=\"val_auc\", patience=10, restore_best_weights=True, mode=\"max\")\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_valid, y_valid),\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        "    callbacks=[early_stopping],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# ✅ 검증 데이터 성능 평가\n",
        "y_valid_pred = model.predict(X_valid).flatten()\n",
        "roc_auc = roc_auc_score(y_valid, y_valid_pred)\n",
        "print(f\"🔥 딥러닝 모델 ROC-AUC: {roc_auc:.6f}\")\n",
        "\n",
        "# ✅ 테스트 데이터 예측\n",
        "y_test_pred = model.predict(X_test_scaled).flatten()\n",
        "\n",
        "# ✅ 제출 파일 생성\n",
        "submission = pd.DataFrame({\"UID\": test_UID, \"채무 불이행 확률\": y_test_pred})\n",
        "submission.to_csv(\"submission.csv\", index=False)\n",
        "\n",
        "print(\"✅ 딥러닝 모델 예측 완료! 결과가 submission.csv에 저장되었습니다.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vuBOAaUstoiy",
        "outputId": "2d965955-38d4-4c73-b74c-6ad53ea3a08a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 26ms/step - auc: 0.5669 - loss: 0.7910 - val_auc: 0.7143 - val_loss: 0.5813\n",
            "Epoch 2/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - auc: 0.6507 - loss: 0.6366 - val_auc: 0.7129 - val_loss: 0.5814\n",
            "Epoch 3/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - auc: 0.6863 - loss: 0.6028 - val_auc: 0.7195 - val_loss: 0.5750\n",
            "Epoch 4/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - auc: 0.6898 - loss: 0.5959 - val_auc: 0.7196 - val_loss: 0.5722\n",
            "Epoch 5/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - auc: 0.7082 - loss: 0.5833 - val_auc: 0.7246 - val_loss: 0.5693\n",
            "Epoch 6/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7013 - loss: 0.5896 - val_auc: 0.7261 - val_loss: 0.5689\n",
            "Epoch 7/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7257 - loss: 0.5652 - val_auc: 0.7284 - val_loss: 0.5661\n",
            "Epoch 8/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7271 - loss: 0.5668 - val_auc: 0.7287 - val_loss: 0.5672\n",
            "Epoch 9/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7161 - loss: 0.5705 - val_auc: 0.7286 - val_loss: 0.5662\n",
            "Epoch 10/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - auc: 0.7162 - loss: 0.5745 - val_auc: 0.7305 - val_loss: 0.5641\n",
            "Epoch 11/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - auc: 0.7287 - loss: 0.5664 - val_auc: 0.7297 - val_loss: 0.5648\n",
            "Epoch 12/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7320 - loss: 0.5607 - val_auc: 0.7307 - val_loss: 0.5641\n",
            "Epoch 13/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7324 - loss: 0.5643 - val_auc: 0.7328 - val_loss: 0.5623\n",
            "Epoch 14/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7248 - loss: 0.5646 - val_auc: 0.7321 - val_loss: 0.5637\n",
            "Epoch 15/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7384 - loss: 0.5585 - val_auc: 0.7326 - val_loss: 0.5625\n",
            "Epoch 16/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7375 - loss: 0.5639 - val_auc: 0.7295 - val_loss: 0.5648\n",
            "Epoch 17/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7401 - loss: 0.5585 - val_auc: 0.7269 - val_loss: 0.5676\n",
            "Epoch 18/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7390 - loss: 0.5540 - val_auc: 0.7289 - val_loss: 0.5662\n",
            "Epoch 19/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7437 - loss: 0.5587 - val_auc: 0.7309 - val_loss: 0.5635\n",
            "Epoch 20/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - auc: 0.7478 - loss: 0.5529 - val_auc: 0.7309 - val_loss: 0.5647\n",
            "Epoch 21/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7431 - loss: 0.5602 - val_auc: 0.7304 - val_loss: 0.5647\n",
            "Epoch 22/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7525 - loss: 0.5517 - val_auc: 0.7333 - val_loss: 0.5625\n",
            "Epoch 23/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7423 - loss: 0.5580 - val_auc: 0.7343 - val_loss: 0.5620\n",
            "Epoch 24/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7538 - loss: 0.5424 - val_auc: 0.7281 - val_loss: 0.5663\n",
            "Epoch 25/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7491 - loss: 0.5487 - val_auc: 0.7315 - val_loss: 0.5634\n",
            "Epoch 26/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7557 - loss: 0.5492 - val_auc: 0.7270 - val_loss: 0.5673\n",
            "Epoch 27/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7515 - loss: 0.5487 - val_auc: 0.7281 - val_loss: 0.5668\n",
            "Epoch 28/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7441 - loss: 0.5521 - val_auc: 0.7286 - val_loss: 0.5676\n",
            "Epoch 29/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7534 - loss: 0.5488 - val_auc: 0.7292 - val_loss: 0.5660\n",
            "Epoch 30/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - auc: 0.7442 - loss: 0.5514 - val_auc: 0.7306 - val_loss: 0.5658\n",
            "Epoch 31/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - auc: 0.7507 - loss: 0.5493 - val_auc: 0.7306 - val_loss: 0.5662\n",
            "Epoch 32/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7655 - loss: 0.5442 - val_auc: 0.7275 - val_loss: 0.5672\n",
            "Epoch 33/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7599 - loss: 0.5422 - val_auc: 0.7287 - val_loss: 0.5668\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            "🔥 딥러닝 모델 ROC-AUC: 0.734086\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "✅ 딥러닝 모델 예측 완료! 결과가 submission.csv에 저장되었습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aCFoCRYCx_EY"
      },
      "execution_count": 2,
      "outputs": []
    }
  ]
}