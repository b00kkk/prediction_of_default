{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "XGr47RvWeK1g"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "XGB"
      ],
      "metadata": {
        "id": "U4iAzNHKW4Ia"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDpOkQ88Rvfd",
        "outputId": "367402b9-616a-4781-f4ee-b08797a9a5b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10000 entries, 0 to 9999\n",
            "Data columns (total 18 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   UID                10000 non-null  object \n",
            " 1   주거 형태              10000 non-null  object \n",
            " 2   연간 소득              10000 non-null  float64\n",
            " 3   현재 직장 근속 연수        10000 non-null  object \n",
            " 4   체납 세금 압류 횟수        10000 non-null  float64\n",
            " 5   개설된 신용계좌 수         10000 non-null  int64  \n",
            " 6   신용 거래 연수           10000 non-null  float64\n",
            " 7   최대 신용한도            10000 non-null  float64\n",
            " 8   신용 문제 발생 횟수        10000 non-null  int64  \n",
            " 9   마지막 연체 이후 경과 개월 수  10000 non-null  int64  \n",
            " 10  개인 파산 횟수           10000 non-null  int64  \n",
            " 11  대출 목적              10000 non-null  object \n",
            " 12  대출 상환 기간           10000 non-null  object \n",
            " 13  현재 대출 잔액           10000 non-null  float64\n",
            " 14  현재 미상환 신용액         10000 non-null  float64\n",
            " 15  월 상환 부채액           10000 non-null  float64\n",
            " 16  신용 점수              10000 non-null  int64  \n",
            " 17  채무 불이행 여부          10000 non-null  int64  \n",
            "dtypes: float64(7), int64(6), object(5)\n",
            "memory usage: 1.4+ MB\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2062 entries, 0 to 2061\n",
            "Data columns (total 17 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   UID                2062 non-null   object \n",
            " 1   주거 형태              2062 non-null   object \n",
            " 2   연간 소득              2062 non-null   float64\n",
            " 3   현재 직장 근속 연수        2062 non-null   object \n",
            " 4   체납 세금 압류 횟수        2062 non-null   float64\n",
            " 5   개설된 신용계좌 수         2062 non-null   int64  \n",
            " 6   신용 거래 연수           2062 non-null   float64\n",
            " 7   최대 신용한도            2062 non-null   float64\n",
            " 8   신용 문제 발생 횟수        2062 non-null   int64  \n",
            " 9   마지막 연체 이후 경과 개월 수  2062 non-null   int64  \n",
            " 10  개인 파산 횟수           2062 non-null   int64  \n",
            " 11  대출 목적              2062 non-null   object \n",
            " 12  대출 상환 기간           2062 non-null   object \n",
            " 13  현재 대출 잔액           2062 non-null   float64\n",
            " 14  현재 미상환 신용액         2062 non-null   float64\n",
            " 15  월 상환 부채액           2062 non-null   float64\n",
            " 16  신용 점수              2062 non-null   int64  \n",
            "dtypes: float64(7), int64(5), object(5)\n",
            "memory usage: 274.0+ KB\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None,\n",
              " None,\n",
              "            UID 주거 형태      연간 소득 현재 직장 근속 연수  체납 세금 압류 횟수  개설된 신용계좌 수  \\\n",
              " 0  TRAIN_00000    자가  1941337.5      10년 이상          0.0           9   \n",
              " 1  TRAIN_00001    월세  1979505.0      10년 이상          0.0           5   \n",
              " 2  TRAIN_00002    월세  1356381.0          4년          0.0          12   \n",
              " 3  TRAIN_00003    월세  1049017.5          6년          0.0          15   \n",
              " 4  TRAIN_00004    월세  4320217.5          2년          0.0          11   \n",
              " \n",
              "    신용 거래 연수   최대 신용한도  신용 문제 발생 횟수  마지막 연체 이후 경과 개월 수  개인 파산 횟수  대출 목적  \\\n",
              " 0      13.4  400597.5            0                 24         1  부채 통합   \n",
              " 1      15.1  360679.5            0                 11         0  부채 통합   \n",
              " 2      18.8  491770.5            1                 74         3  부채 통합   \n",
              " 3      14.8  411546.0            1                 22         1  부채 통합   \n",
              " 4      26.1  895288.5            0                 32         0  부채 통합   \n",
              " \n",
              "   대출 상환 기간   현재 대출 잔액  현재 미상환 신용액  월 상환 부채액  신용 점수  채무 불이행 여부  \n",
              " 0    단기 상환   390903.0    225457.5    8806.5    767          0  \n",
              " 1    단기 상환  1002184.5     64749.0   24961.5    767          0  \n",
              " 2    단기 상환   227775.0    487644.0   12069.0    800          1  \n",
              " 3    단기 상환   251383.5    413211.0   31749.0    796          1  \n",
              " 4    장기 상환  1163176.5     78991.5    5862.0    751          0  )"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 파일 경로\n",
        "train_path = \"train.csv\"\n",
        "test_path = \"test.csv\"\n",
        "\n",
        "# 데이터 로드\n",
        "train_df = pd.read_csv(train_path)\n",
        "test_df = pd.read_csv(test_path)\n",
        "\n",
        "# 데이터 구조 확인\n",
        "train_info = train_df.info()\n",
        "test_info = test_df.info()\n",
        "\n",
        "# train 데이터 상위 5개 확인\n",
        "train_head = train_df.head()\n",
        "\n",
        "train_info, test_info, train_head"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "\n",
        "# 1. 불필요한 컬럼 제거\n",
        "train_df = train_df.drop(columns=[\"UID\"])\n",
        "test_UID=test_df.pop('UID')\n",
        "\n",
        "# 2. 범주형 변수 처리 (레이블 인코딩)\n",
        "categorical_cols = [\"주거 형태\", \"현재 직장 근속 연수\", \"대출 목적\", \"대출 상환 기간\"]\n",
        "label_encoders = {}\n",
        "\n",
        "for col in categorical_cols:\n",
        "    le = LabelEncoder()\n",
        "    train_df[col] = le.fit_transform(train_df[col])\n",
        "    test_df[col] = le.transform(test_df[col])\n",
        "    label_encoders[col] = le\n",
        "\n",
        "# 3. 특징(X)과 타겟(y) 분리\n",
        "X = train_df.drop(columns=[\"채무 불이행 여부\"])\n",
        "y = train_df[\"채무 불이행 여부\"]\n",
        "X_test = test_df.copy()\n",
        "\n",
        "# 4. 데이터 분할 (학습용/검증용)\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# 5. 스케일링 (표준화)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_valid_scaled = scaler.transform(X_valid)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# 데이터 전처리 완료\n",
        "X_train_scaled.shape, X_valid_scaled.shape, X_test_scaled.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1NRls1gSXkS",
        "outputId": "96bc6f2f-061f-40c6-af93-35b4b211f8fe"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((8000, 16), (2000, 16), (2062, 16))"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# XGBoost 모델 학습\n",
        "model = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric=\"logloss\")\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# 검증 데이터에 대한 예측\n",
        "y_valid_pred = model.predict_proba(X_valid_scaled)[:, 1]\n",
        "\n",
        "# ROC-AUC 평가\n",
        "roc_auc = roc_auc_score(y_valid, y_valid_pred)\n",
        "roc_auc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5MQeEvPaSaw8",
        "outputId": "c9bfd8a3-ac8c-4137-83ad-2e35c7140222"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7058504176326879"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# XGBoost 하이퍼파라미터 튜닝을 위한 파라미터 그리드\n",
        "param_grid = {\n",
        "    \"n_estimators\": [100, 200, 300],\n",
        "    \"max_depth\": [3, 5, 7],\n",
        "    \"learning_rate\": [0.01, 0.05, 0.1],\n",
        "    \"subsample\": [0.7, 0.8, 0.9],\n",
        "    \"colsample_bytree\": [0.7, 0.8, 0.9]\n",
        "}\n",
        "\n",
        "# RandomizedSearchCV 실행\n",
        "xgb = XGBClassifier(random_state=42, eval_metric=\"logloss\", use_label_encoder=False)\n",
        "random_search = RandomizedSearchCV(xgb, param_grid, n_iter=10, scoring=\"roc_auc\", cv=3, random_state=42, n_jobs=-1)\n",
        "random_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "# 최적 파라미터 및 성능 확인\n",
        "best_params = random_search.best_params_\n",
        "best_score = random_search.best_score_\n",
        "\n",
        "best_params, best_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEPZdMdzSlM7",
        "outputId": "f7084ec9-30c5-4673-83e3-727f169bcce1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'subsample': 0.9,\n",
              "  'n_estimators': 200,\n",
              "  'max_depth': 3,\n",
              "  'learning_rate': 0.05,\n",
              "  'colsample_bytree': 0.8},\n",
              " 0.7427826617478358)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 최적 하이퍼파라미터로 XGBoost 모델 재학습\n",
        "best_model = XGBClassifier(**best_params, random_state=42, eval_metric=\"logloss\")\n",
        "best_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# 검증 데이터 평가\n",
        "y_valid_pred = best_model.predict_proba(X_valid_scaled)[:, 1]\n",
        "roc_auc_final = roc_auc_score(y_valid, y_valid_pred)\n",
        "\n",
        "# 테스트 데이터 예측\n",
        "y_test_pred = best_model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "roc_auc_final"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IElvX8f1S4iZ",
        "outputId": "fcd92687-8012-46c6-c21d-0cac0869a4a0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.750733137829912"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 예측 결과 저장\n",
        "result10 = pd.DataFrame({\"UID\": test_UID, \"채무 불이행 확률\": y_test_pred})\n",
        "result10.to_csv(\"result10.csv\", index=False)"
      ],
      "metadata": {
        "id": "uH5nTyBiTOqj"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "XGB2"
      ],
      "metadata": {
        "id": "U8B7UoKAW6tP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 데이터 다시 로드\n",
        "train_path = \"train.csv\"\n",
        "test_path = \"test.csv\"\n",
        "\n",
        "train_df = pd.read_csv(train_path)\n",
        "test_df = pd.read_csv(test_path)\n",
        "\n",
        "# 데이터 확인\n",
        "train_df.head(), test_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_SlELKWVA2H",
        "outputId": "a612ec62-9d87-4d88-afb1-57f14b157e98"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(           UID 주거 형태      연간 소득 현재 직장 근속 연수  체납 세금 압류 횟수  개설된 신용계좌 수  \\\n",
              " 0  TRAIN_00000    자가  1941337.5      10년 이상          0.0           9   \n",
              " 1  TRAIN_00001    월세  1979505.0      10년 이상          0.0           5   \n",
              " 2  TRAIN_00002    월세  1356381.0          4년          0.0          12   \n",
              " 3  TRAIN_00003    월세  1049017.5          6년          0.0          15   \n",
              " 4  TRAIN_00004    월세  4320217.5          2년          0.0          11   \n",
              " \n",
              "    신용 거래 연수   최대 신용한도  신용 문제 발생 횟수  마지막 연체 이후 경과 개월 수  개인 파산 횟수  대출 목적  \\\n",
              " 0      13.4  400597.5            0                 24         1  부채 통합   \n",
              " 1      15.1  360679.5            0                 11         0  부채 통합   \n",
              " 2      18.8  491770.5            1                 74         3  부채 통합   \n",
              " 3      14.8  411546.0            1                 22         1  부채 통합   \n",
              " 4      26.1  895288.5            0                 32         0  부채 통합   \n",
              " \n",
              "   대출 상환 기간   현재 대출 잔액  현재 미상환 신용액  월 상환 부채액  신용 점수  채무 불이행 여부  \n",
              " 0    단기 상환   390903.0    225457.5    8806.5    767          0  \n",
              " 1    단기 상환  1002184.5     64749.0   24961.5    767          0  \n",
              " 2    단기 상환   227775.0    487644.0   12069.0    800          1  \n",
              " 3    단기 상환   251383.5    413211.0   31749.0    796          1  \n",
              " 4    장기 상환  1163176.5     78991.5    5862.0    751          0  ,\n",
              "          UID            주거 형태      연간 소득 현재 직장 근속 연수  체납 세금 압류 횟수  개설된 신용계좌 수  \\\n",
              " 0  TEST_0000               월세  1560090.0      10년 이상          0.0          13   \n",
              " 1  TEST_0001  주택 담보 대출 (거주 중)  2102616.0          2년          0.0           9   \n",
              " 2  TEST_0002  주택 담보 대출 (거주 중)  2477989.5      10년 이상          0.0          11   \n",
              " 3  TEST_0003  주택 담보 대출 (거주 중)  1571091.0          6년          0.0           7   \n",
              " 4  TEST_0004  주택 담보 대출 (거주 중)  2290260.0      10년 이상          0.0          19   \n",
              " \n",
              "    신용 거래 연수    최대 신용한도  신용 문제 발생 횟수  마지막 연체 이후 경과 개월 수  개인 파산 횟수  대출 목적  \\\n",
              " 0      12.0   495561.0            0                 18         0     기타   \n",
              " 1      29.0   580833.0            0                 40         0  부채 통합   \n",
              " 2      26.5   995841.0            0                 44         0  부채 통합   \n",
              " 3      34.4   601656.0            0                 45         0  부채 통합   \n",
              " 4      25.0  1954623.0            0                 14         0  부채 통합   \n",
              " \n",
              "   대출 상환 기간  현재 대출 잔액  현재 미상환 신용액  월 상환 부채액  신용 점수  \n",
              " 0    단기 상환  376332.0    133522.5   29641.5    736  \n",
              " 1    장기 상환  830379.0    302983.5   20151.0    718  \n",
              " 2    장기 상환  877635.0    379278.0   13113.0    722  \n",
              " 3    단기 상환  487278.0    275395.5   11679.0    762  \n",
              " 4    단기 상환  397782.0    742767.0   42370.5    775  )"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 목표 변수 분리\n",
        "X = train_df.drop(columns=[\"UID\", \"채무 불이행 여부\"])\n",
        "y = train_df[\"채무 불이행 여부\"]\n",
        "\n",
        "# 테스트 데이터 준비 (UID 제외)\n",
        "test_UID=test_df.pop('UID')\n",
        "X_test=test_df\n",
        "\n",
        "# 범주형 변수 인코딩\n",
        "categorical_cols = [\"주거 형태\", \"현재 직장 근속 연수\", \"대출 목적\", \"대출 상환 기간\"]\n",
        "encoder = OneHotEncoder(sparse_output=False, drop=\"first\")\n",
        "\n",
        "# 먼저 fit()을 실행하여 encoder를 학습\n",
        "encoder.fit(X[categorical_cols])\n",
        "\n",
        "# 변환 적용\n",
        "X_encoded = encoder.transform(X[categorical_cols])\n",
        "X_test_encoded = encoder.transform(X_test[categorical_cols])\n",
        "\n",
        "# 인코딩된 컬럼명을 가져오기\n",
        "encoded_cols = encoder.get_feature_names_out(categorical_cols)\n",
        "\n",
        "# DataFrame으로 변환\n",
        "X_encoded_df = pd.DataFrame(X_encoded, columns=encoded_cols, index=X.index)\n",
        "X_test_encoded_df = pd.DataFrame(X_test_encoded, columns=encoded_cols, index=X_test.index)\n",
        "\n",
        "# 기존 데이터에서 범주형 변수 제거 후 결합\n",
        "X = X.drop(columns=categorical_cols).reset_index(drop=True)\n",
        "X_test = X_test.drop(columns=categorical_cols).reset_index(drop=True)\n",
        "\n",
        "X = pd.concat([X, X_encoded_df], axis=1)\n",
        "X_test = pd.concat([X_test, X_test_encoded_df], axis=1)\n",
        "\n",
        "# 데이터 스케일링\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# 훈련 데이터 분할 (Train / Validation)\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 데이터 전처리 완료\n",
        "X_train.shape, X_valid.shape, X_test_scaled.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LkVsU1BoXAEx",
        "outputId": "456f8d0b-be9b-4030-8317-6e267cf9da09"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((8000, 39), (2000, 39), (2062, 39))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "import numpy as np\n",
        "\n",
        "# XGBoost 모델 학습 (기본 설정)\n",
        "model = XGBClassifier(random_state=42, eval_metric=\"logloss\")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 특성 중요도 가져오기\n",
        "feature_importances = model.feature_importances_\n",
        "feature_names = X.columns\n",
        "\n",
        "# 중요도 높은 순서로 정렬\n",
        "important_features = pd.DataFrame({\"Feature\": feature_names, \"Importance\": feature_importances})\n",
        "important_features = important_features.sort_values(by=\"Importance\", ascending=False)\n",
        "\n",
        "# 상위 10개 특성 출력\n",
        "important_features.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "pG4yAdQ2XS2G",
        "outputId": "ad539a50-ee0d-41dd-bd36-1cd27afaf6e0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           Feature  Importance\n",
              "28     대출 목적_부채 통합    0.152295\n",
              "38  대출 상환 기간_장기 상환    0.055755\n",
              "15  현재 직장 근속 연수_1년    0.041954\n",
              "17  현재 직장 근속 연수_2년    0.041669\n",
              "5      신용 문제 발생 횟수    0.038840\n",
              "21  현재 직장 근속 연수_6년    0.038352\n",
              "2       개설된 신용계좌 수    0.037350\n",
              "7         개인 파산 횟수    0.032672\n",
              "0            연간 소득    0.031364\n",
              "18  현재 직장 근속 연수_3년    0.027866"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7a02457c-04bd-4fb6-8f74-9129a8036f48\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Feature</th>\n",
              "      <th>Importance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>대출 목적_부채 통합</td>\n",
              "      <td>0.152295</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>대출 상환 기간_장기 상환</td>\n",
              "      <td>0.055755</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>현재 직장 근속 연수_1년</td>\n",
              "      <td>0.041954</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>현재 직장 근속 연수_2년</td>\n",
              "      <td>0.041669</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>신용 문제 발생 횟수</td>\n",
              "      <td>0.038840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>현재 직장 근속 연수_6년</td>\n",
              "      <td>0.038352</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>개설된 신용계좌 수</td>\n",
              "      <td>0.037350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>개인 파산 횟수</td>\n",
              "      <td>0.032672</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>연간 소득</td>\n",
              "      <td>0.031364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>현재 직장 근속 연수_3년</td>\n",
              "      <td>0.027866</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7a02457c-04bd-4fb6-8f74-9129a8036f48')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7a02457c-04bd-4fb6-8f74-9129a8036f48 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7a02457c-04bd-4fb6-8f74-9129a8036f48');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d4d7bcf9-a160-4bf2-8a7e-ff37f08ecf88\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d4d7bcf9-a160-4bf2-8a7e-ff37f08ecf88')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d4d7bcf9-a160-4bf2-8a7e-ff37f08ecf88 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "important_features",
              "summary": "{\n  \"name\": \"important_features\",\n  \"rows\": 39,\n  \"fields\": [\n    {\n      \"column\": \"Feature\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 39,\n        \"samples\": [\n          \"\\ub300\\ucd9c \\ubaa9\\uc801_\\uc5ec\\ud589 \\uc790\\uae08\",\n          \"\\ub300\\ucd9c \\ubaa9\\uc801_\\uad50\\uc721\\ube44\",\n          \"\\uc2e0\\uc6a9 \\ubb38\\uc81c \\ubc1c\\uc0dd \\ud69f\\uc218\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Importance\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 37,\n        \"samples\": [\n          0.022872956469655037,\n          0.025307027623057365,\n          0.03884023055434227\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 중요도 0.02 이하 제거\n",
        "low_importance_features = important_features[important_features[\"Importance\"] < 0.02][\"Feature\"].tolist()\n",
        "X = X.drop(columns=low_importance_features)\n",
        "X_test = X_test.drop(columns=low_importance_features)\n",
        "\n",
        "# 데이터 재스케일링\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# 훈련 데이터 재분할\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# XGBoost 하이퍼파라미터 튜닝\n",
        "param_grid = {\n",
        "    \"n_estimators\": [100, 300, 500],\n",
        "    \"max_depth\": [3, 5, 7],\n",
        "    \"learning_rate\": [0.01, 0.05, 0.1],\n",
        "    \"subsample\": [0.7, 0.8, 0.9],\n",
        "    \"colsample_bytree\": [0.7, 0.8, 0.9]\n",
        "}\n",
        "\n",
        "xgb = XGBClassifier(random_state=42, eval_metric=\"logloss\")\n",
        "random_search = RandomizedSearchCV(xgb, param_grid, n_iter=10, scoring=\"roc_auc\", cv=3, random_state=42, n_jobs=-1)\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# 최적 파라미터로 모델 재학습\n",
        "best_params = random_search.best_params_\n",
        "best_model = XGBClassifier(**best_params, random_state=42, eval_metric=\"logloss\")\n",
        "best_model.fit(X_train, y_train)\n",
        "\n",
        "# 검증 데이터 평가\n",
        "y_valid_pred = best_model.predict_proba(X_valid)[:, 1]\n",
        "roc_auc_final = roc_auc_score(y_valid, y_valid_pred)\n",
        "\n",
        "# 테스트 데이터 예측\n",
        "y_test_pred = best_model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "# 최종 ROC-AUC 값 확인\n",
        "roc_auc_final"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alHrMM9jYQ9A",
        "outputId": "283916a8-7c5b-4a2c-dad7-301e7377c62d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7433933771977133"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DNimE9smLsd",
        "outputId": "7a25bf84-4254-45ad-c3ce-3c8fc85e8d5c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: catboost in /usr/local/lib/python3.11/dist-packages (1.2.7)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from catboost) (1.26.4)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from catboost) (1.14.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (3.2.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost) (9.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import shap\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from xgboost import XGBClassifier\n",
        "import dask\n",
        "import lightgbm as lgb\n",
        "import catboost as cb\n",
        "\n",
        "# 데이터 로드\n",
        "train_path = \"train.csv\"\n",
        "test_path = \"test.csv\"\n",
        "\n",
        "train_df = pd.read_csv(train_path)\n",
        "test_df = pd.read_csv(test_path)\n",
        "\n",
        "# 목표 변수 분리\n",
        "X = train_df.drop(columns=[\"UID\", \"채무 불이행 여부\"])\n",
        "y = train_df[\"채무 불이행 여부\"]\n",
        "\n",
        "# 테스트 데이터 준비 (UID 제외)\n",
        "test_UID = test_df.pop(\"UID\")\n",
        "X_test = test_df\n",
        "\n",
        "# 범주형 변수 인코딩\n",
        "categorical_cols = [\"주거 형태\", \"현재 직장 근속 연수\", \"대출 목적\", \"대출 상환 기간\"]\n",
        "encoder = OneHotEncoder(sparse_output=False, drop=\"first\")\n",
        "\n",
        "# 변환 적용\n",
        "X_encoded = encoder.fit_transform(X[categorical_cols])\n",
        "X_test_encoded = encoder.transform(X_test[categorical_cols])\n",
        "\n",
        "# 인코딩된 컬럼명을 가져오기\n",
        "encoded_cols = encoder.get_feature_names_out(categorical_cols)\n",
        "\n",
        "# DataFrame으로 변환\n",
        "X_encoded_df = pd.DataFrame(X_encoded, columns=encoded_cols, index=X.index)\n",
        "X_test_encoded_df = pd.DataFrame(X_test_encoded, columns=encoded_cols, index=X_test.index)\n",
        "\n",
        "# 기존 데이터에서 범주형 변수 제거 후 결합\n",
        "X = X.drop(columns=categorical_cols).reset_index(drop=True)\n",
        "X_test = X_test.drop(columns=categorical_cols).reset_index(drop=True)\n",
        "\n",
        "X = pd.concat([X, X_encoded_df], axis=1)\n",
        "X_test = pd.concat([X_test, X_test_encoded_df], axis=1)\n",
        "\n",
        "# 데이터 스케일링\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# 훈련 데이터 분할 (Train / Validation)\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# XGBoost 모델 학습 (기본 설정)\n",
        "xgb_model = XGBClassifier(random_state=42, eval_metric=\"logloss\")\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# SHAP 분석을 위한 객체 생성\n",
        "explainer = shap.Explainer(xgb_model, X_train)\n",
        "shap_values = explainer(X_train)\n",
        "\n",
        "# 평균 절대 SHAP 값 계산 (특성 중요도)\n",
        "shap_importance = np.abs(shap_values.values).mean(axis=0)\n",
        "\n",
        "# SHAP 값이 작은 (중요도가 낮은) 특성 제거\n",
        "threshold = np.percentile(shap_importance, 25)  # 하위 25% 특성 제거\n",
        "low_shap_features = X.columns[shap_importance < threshold]\n",
        "\n",
        "# 중요도가 낮은 특성 제거\n",
        "X = X.drop(columns=low_shap_features)\n",
        "X_test = X_test.drop(columns=low_shap_features)\n",
        "\n",
        "# 데이터 재스케일링\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# 훈련 데이터 재분할\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# XGBoost, LightGBM, CatBoost 비교\n",
        "models = {\n",
        "    \"XGBoost\": XGBClassifier(n_estimators=300, max_depth=5, learning_rate=0.05, subsample=0.8,\n",
        "                             colsample_bytree=0.8, min_child_weight=3, gamma=0.1, scale_pos_weight=1.2,\n",
        "                             random_state=42, eval_metric=\"logloss\"),\n",
        "    \"LightGBM\": lgb.LGBMClassifier(n_estimators=300, max_depth=5, learning_rate=0.05, subsample=0.8,\n",
        "                                   colsample_bytree=0.8, min_child_weight=3, reg_alpha=0.1,\n",
        "                                   random_state=42,verbose=-1),\n",
        "    \"CatBoost\": cb.CatBoostClassifier(n_estimators=300, depth=5, learning_rate=0.05, subsample=0.8,\n",
        "                                      colsample_bylevel=0.8, l2_leaf_reg=3, random_seed=42, verbose=0)\n",
        "}\n",
        "\n",
        "# K-Fold Cross Validation을 사용하여 성능 비교\n",
        "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "results = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    scores = cross_val_score(model, X_train, y_train, cv=kfold, scoring=\"roc_auc\", n_jobs=-1)\n",
        "    results[name] = np.mean(scores)\n",
        "\n",
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqagomnHY6uy",
        "outputId": "b4f20299-c5df-49d5-b1dd-901f3d150d03"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 99%|===================| 7889/8000 [01:04<00:00]       "
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'XGBoost': 0.7370873907875806,\n",
              " 'LightGBM': 0.7346066962765254,\n",
              " 'CatBoost': 0.7482797089058948}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "\n",
        "# 🎯 XGBoost 최적 파라미터 찾기\n",
        "xgb_param_grid = {\n",
        "    \"n_estimators\": [100, 300, 500],\n",
        "    \"max_depth\": [3, 5, 7],\n",
        "    \"learning_rate\": [0.01, 0.05, 0.1],\n",
        "    \"subsample\": [0.7, 0.8, 0.9],\n",
        "    \"colsample_bytree\": [0.7, 0.8, 0.9]\n",
        "}\n",
        "xgb = XGBClassifier(random_state=42, eval_metric=\"logloss\")\n",
        "xgb_search = RandomizedSearchCV(xgb, xgb_param_grid, n_iter=10, scoring=\"roc_auc\", cv=3, random_state=42, n_jobs=-1)\n",
        "xgb_search.fit(X_train, y_train)\n",
        "best_xgb_params = xgb_search.best_params_\n",
        "\n",
        "# 🎯 LightGBM 최적 파라미터 찾기\n",
        "lgb_param_grid = {\n",
        "    \"n_estimators\": [100, 300, 500],\n",
        "    \"max_depth\": [3, 5, 7],\n",
        "    \"learning_rate\": [0.01, 0.05, 0.1],\n",
        "    \"subsample\": [0.7, 0.8, 0.9],\n",
        "    \"colsample_bytree\": [0.7, 0.8, 0.9]\n",
        "}\n",
        "lgb = LGBMClassifier(random_state=42, verbose=-1)\n",
        "lgb_search = RandomizedSearchCV(lgb, lgb_param_grid, n_iter=10, scoring=\"roc_auc\", cv=3, random_state=42, n_jobs=-1)\n",
        "lgb_search.fit(X_train, y_train)\n",
        "best_lgb_params = lgb_search.best_params_\n",
        "\n",
        "# 🎯 CatBoost 최적 파라미터 찾기\n",
        "cat_param_grid = {\n",
        "    \"iterations\": [100, 300, 500],\n",
        "    \"depth\": [3, 5, 7],\n",
        "    \"learning_rate\": [0.01, 0.05, 0.1]\n",
        "}\n",
        "cat = CatBoostClassifier(random_state=42, verbose=0)\n",
        "cat_search = RandomizedSearchCV(cat, cat_param_grid, n_iter=10, scoring=\"roc_auc\", cv=3, random_state=42, n_jobs=-1)\n",
        "cat_search.fit(X_train, y_train)\n",
        "best_cat_params = cat_search.best_params_"
      ],
      "metadata": {
        "id": "LHGEQPRqciOi"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "\n",
        "# 각 모델의 최적 파라미터 사용 (이미 튜닝된 best_params 적용)\n",
        "xgb_model = XGBClassifier(**best_xgb_params, random_state=42, eval_metric=\"logloss\")\n",
        "lgb_model = LGBMClassifier(**best_lgb_params, random_state=42, verbose=-1)\n",
        "cat_model = CatBoostClassifier(**best_cat_params, random_state=42, verbose=0)\n",
        "\n",
        "# 모델 학습\n",
        "xgb_model.fit(X_train, y_train)\n",
        "lgb_model.fit(X_train, y_train)\n",
        "cat_model.fit(X_train, y_train)\n",
        "\n",
        "# 검증 데이터 예측 (확률 값 추출)\n",
        "y_valid_xgb = xgb_model.predict_proba(X_valid)[:, 1]\n",
        "y_valid_lgb = lgb_model.predict_proba(X_valid)[:, 1]\n",
        "y_valid_cat = cat_model.predict_proba(X_valid)[:, 1]\n",
        "\n",
        "# Soft Voting (가중 평균)\n",
        "final_valid_pred = (0.3 * y_valid_xgb) + (0.2 * y_valid_lgb) + (0.5 * y_valid_cat)\n",
        "\n",
        "# 최종 성능 평가\n",
        "roc_auc_ensemble = roc_auc_score(y_valid, final_valid_pred)\n",
        "print(\"앙상블 모델 ROC-AUC:\", roc_auc_ensemble)\n",
        "\n",
        "# 테스트 데이터 예측\n",
        "y_test_xgb = xgb_model.predict_proba(X_test_scaled)[:, 1]\n",
        "y_test_lgb = lgb_model.predict_proba(X_test_scaled)[:, 1]\n",
        "y_test_cat = cat_model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "# 최종 테스트 데이터 예측 (가중 평균)\n",
        "y_test_final = (0.3 * y_test_xgb) + (0.2 * y_test_lgb) + (0.5 * y_test_cat)\n",
        "\n",
        "# 제출 파일 생성\n",
        "submission = pd.DataFrame({\"UID\": test_UID, \"채무 불이행 확률\": y_test_final})\n",
        "submission.to_csv(\"submission.csv\", index=False)\n",
        "\n",
        "print(\"앙상블 모델 예측 완료! 결과가 submission.csv에 저장되었습니다.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VKm8APcaMtd",
        "outputId": "574fa2ee-5302-48e9-97f0-c912663a8e1e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "앙상블 모델 ROC-AUC: 0.7570076406534383\n",
            "앙상블 모델 예측 완료! 결과가 submission.csv에 저장되었습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3번째"
      ],
      "metadata": {
        "id": "fEVFwvZ2ng_C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7HgrSmdT2Gn",
        "outputId": "8864b323-054a-48a1-dc8d-c4854211ece6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.2.1-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.15.1-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.39)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.9-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.11/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
            "Downloading optuna-4.2.1-py3-none-any.whl (383 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.6/383.6 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.15.1-py3-none-any.whl (231 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.8/231.8 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading Mako-1.3.9-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.3.9 alembic-1.15.1 colorlog-6.9.0 optuna-4.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "def objective(trial):\n",
        "    w_xgb = trial.suggest_float(\"w_xgb\", 0.1, 0.6)\n",
        "    w_lgb = trial.suggest_float(\"w_lgb\", 0.1, 0.6)\n",
        "    w_cat = 1.0 - (w_xgb + w_lgb)\n",
        "\n",
        "    final_pred = (w_xgb * y_valid_xgb) + (w_lgb * y_valid_lgb) + (w_cat * y_valid_cat)\n",
        "    return roc_auc_score(y_valid, final_pred)\n",
        "\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=50)\n",
        "best_weights = study.best_params\n",
        "print(\"최적 가중치:\", best_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hbVlmbBsJ40",
        "outputId": "60a399ac-9612-4c58-90b6-4fef26fdf2c8"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-03-18 08:13:19,478] A new study created in memory with name: no-name-6c243a7a-81ee-440e-96f6-1a4b48119fc0\n",
            "[I 2025-03-18 08:13:19,491] Trial 0 finished with value: 0.7572713032720865 and parameters: {'w_xgb': 0.2458860897980126, 'w_lgb': 0.2495954226880451}. Best is trial 0 with value: 0.7572713032720865.\n",
            "[I 2025-03-18 08:13:19,498] Trial 1 finished with value: 0.7581991286896079 and parameters: {'w_xgb': 0.15183635572740375, 'w_lgb': 0.5014933215695758}. Best is trial 1 with value: 0.7581991286896079.\n",
            "[I 2025-03-18 08:13:19,505] Trial 2 finished with value: 0.7576017159207722 and parameters: {'w_xgb': 0.2358762068370164, 'w_lgb': 0.32575451053839954}. Best is trial 1 with value: 0.7581991286896079.\n",
            "[I 2025-03-18 08:13:19,511] Trial 3 finished with value: 0.7565893404652033 and parameters: {'w_xgb': 0.35536732546031746, 'w_lgb': 0.1526371343960223}. Best is trial 1 with value: 0.7581991286896079.\n",
            "[I 2025-03-18 08:13:19,517] Trial 4 finished with value: 0.7580378161170173 and parameters: {'w_xgb': 0.25647921981209065, 'w_lgb': 0.4094378466625249}. Best is trial 1 with value: 0.7581991286896079.\n",
            "[I 2025-03-18 08:13:19,522] Trial 5 finished with value: 0.7579543785794702 and parameters: {'w_xgb': 0.486724745229154, 'w_lgb': 0.3566714280974097}. Best is trial 1 with value: 0.7581991286896079.\n",
            "[I 2025-03-18 08:13:19,529] Trial 6 finished with value: 0.7564347028956163 and parameters: {'w_xgb': 0.4741223634266123, 'w_lgb': 0.11365957781562694}. Best is trial 1 with value: 0.7581991286896079.\n",
            "[I 2025-03-18 08:13:19,537] Trial 7 finished with value: 0.7578409035284066 and parameters: {'w_xgb': 0.3627400472760225, 'w_lgb': 0.34695326669218385}. Best is trial 1 with value: 0.7581991286896079.\n",
            "[I 2025-03-18 08:13:19,543] Trial 8 finished with value: 0.7577318784793453 and parameters: {'w_xgb': 0.14476410555494776, 'w_lgb': 0.35639570082992633}. Best is trial 1 with value: 0.7581991286896079.\n",
            "[I 2025-03-18 08:13:19,549] Trial 9 finished with value: 0.7582814537266543 and parameters: {'w_xgb': 0.3770945980923619, 'w_lgb': 0.4993860836869689}. Best is trial 9 with value: 0.7582814537266543.\n",
            "[I 2025-03-18 08:13:19,564] Trial 10 finished with value: 0.7582580912161411 and parameters: {'w_xgb': 0.5951130601569574, 'w_lgb': 0.5737528841681139}. Best is trial 9 with value: 0.7582814537266543.\n",
            "[I 2025-03-18 08:13:19,579] Trial 11 finished with value: 0.7582770037246517 and parameters: {'w_xgb': 0.5977055764632883, 'w_lgb': 0.5923847506234786}. Best is trial 9 with value: 0.7582814537266543.\n",
            "[I 2025-03-18 08:13:19,594] Trial 12 finished with value: 0.7582692162211473 and parameters: {'w_xgb': 0.577697508015839, 'w_lgb': 0.59422318216895}. Best is trial 9 with value: 0.7582814537266543.\n",
            "[I 2025-03-18 08:13:19,608] Trial 13 finished with value: 0.7582703287216479 and parameters: {'w_xgb': 0.4485737902655724, 'w_lgb': 0.49398266432590643}. Best is trial 9 with value: 0.7582814537266543.\n",
            "[I 2025-03-18 08:13:19,622] Trial 14 finished with value: 0.7582814537266542 and parameters: {'w_xgb': 0.519927929761919, 'w_lgb': 0.5069514825721805}. Best is trial 9 with value: 0.7582814537266543.\n",
            "[I 2025-03-18 08:13:19,636] Trial 15 finished with value: 0.7582859037286567 and parameters: {'w_xgb': 0.4135692239994529, 'w_lgb': 0.4791597324213138}. Best is trial 15 with value: 0.7582859037286567.\n",
            "[I 2025-03-18 08:13:19,651] Trial 16 finished with value: 0.7581279286575678 and parameters: {'w_xgb': 0.40371940282968655, 'w_lgb': 0.441891040567136}. Best is trial 15 with value: 0.7582859037286567.\n",
            "[I 2025-03-18 08:13:19,668] Trial 17 finished with value: 0.758047828621523 and parameters: {'w_xgb': 0.2866527027942661, 'w_lgb': 0.43551141492869083}. Best is trial 15 with value: 0.7582859037286567.\n",
            "[I 2025-03-18 08:13:19,683] Trial 18 finished with value: 0.7583237287456779 and parameters: {'w_xgb': 0.3081027433101561, 'w_lgb': 0.531472888652562}. Best is trial 18 with value: 0.7583237287456779.\n",
            "[I 2025-03-18 08:13:19,704] Trial 19 finished with value: 0.7583337412501835 and parameters: {'w_xgb': 0.31530127555629966, 'w_lgb': 0.5355334150327926}. Best is trial 19 with value: 0.7583337412501835.\n",
            "[I 2025-03-18 08:13:19,722] Trial 20 finished with value: 0.758311491240171 and parameters: {'w_xgb': 0.310756097897519, 'w_lgb': 0.5364841841624902}. Best is trial 19 with value: 0.7583337412501835.\n",
            "[I 2025-03-18 08:13:19,738] Trial 21 finished with value: 0.7583181662431747 and parameters: {'w_xgb': 0.31028056667913556, 'w_lgb': 0.5488117583728059}. Best is trial 19 with value: 0.7583337412501835.\n",
            "[I 2025-03-18 08:13:19,753] Trial 22 finished with value: 0.7583537662591948 and parameters: {'w_xgb': 0.20206168963329096, 'w_lgb': 0.5597833740559003}. Best is trial 22 with value: 0.7583537662591948.\n",
            "[I 2025-03-18 08:13:19,767] Trial 23 finished with value: 0.75829146623116 and parameters: {'w_xgb': 0.1942668994643177, 'w_lgb': 0.5499378309728051}. Best is trial 22 with value: 0.7583537662591948.\n",
            "[I 2025-03-18 08:13:19,781] Trial 24 finished with value: 0.7580889911400459 and parameters: {'w_xgb': 0.1835145794484151, 'w_lgb': 0.4460599183078907}. Best is trial 22 with value: 0.7583537662591948.\n",
            "[I 2025-03-18 08:13:19,795] Trial 25 finished with value: 0.7573336033001213 and parameters: {'w_xgb': 0.10087360689691424, 'w_lgb': 0.28474966703139704}. Best is trial 22 with value: 0.7583537662591948.\n",
            "[I 2025-03-18 08:13:19,810] Trial 26 finished with value: 0.7579632785834755 and parameters: {'w_xgb': 0.3172252750609948, 'w_lgb': 0.39640227555825436}. Best is trial 22 with value: 0.7583537662591948.\n",
            "[I 2025-03-18 08:13:19,826] Trial 27 finished with value: 0.7582948037326618 and parameters: {'w_xgb': 0.21622155480160604, 'w_lgb': 0.5363723336647243}. Best is trial 22 with value: 0.7583537662591948.\n",
            "[I 2025-03-18 08:13:19,842] Trial 28 finished with value: 0.7581446161650773 and parameters: {'w_xgb': 0.2736539453624467, 'w_lgb': 0.47065705693969334}. Best is trial 22 with value: 0.7583537662591948.\n",
            "[I 2025-03-18 08:13:19,857] Trial 29 finished with value: 0.7583826912722109 and parameters: {'w_xgb': 0.2460630741217689, 'w_lgb': 0.5669559135806916}. Best is trial 29 with value: 0.7583826912722109.\n",
            "[I 2025-03-18 08:13:19,873] Trial 30 finished with value: 0.758409391284226 and parameters: {'w_xgb': 0.23322840058758815, 'w_lgb': 0.5671687826636663}. Best is trial 30 with value: 0.758409391284226.\n",
            "[I 2025-03-18 08:13:19,888] Trial 31 finished with value: 0.7584149537867292 and parameters: {'w_xgb': 0.23263038132620692, 'w_lgb': 0.5720780559269026}. Best is trial 31 with value: 0.7584149537867292.\n",
            "[I 2025-03-18 08:13:19,904] Trial 32 finished with value: 0.7583237287456779 and parameters: {'w_xgb': 0.16322954366286957, 'w_lgb': 0.5624066714495387}. Best is trial 31 with value: 0.7584149537867292.\n",
            "[I 2025-03-18 08:13:19,919] Trial 33 finished with value: 0.7584016037807219 and parameters: {'w_xgb': 0.23473016936259167, 'w_lgb': 0.5990748471695854}. Best is trial 31 with value: 0.7584149537867292.\n",
            "[I 2025-03-18 08:13:19,935] Trial 34 finished with value: 0.7583904787757154 and parameters: {'w_xgb': 0.24067337696988145, 'w_lgb': 0.5988879194210048}. Best is trial 31 with value: 0.7584149537867292.\n",
            "[I 2025-03-18 08:13:19,949] Trial 35 finished with value: 0.7570488031719614 and parameters: {'w_xgb': 0.23298760980868924, 'w_lgb': 0.2203374141252754}. Best is trial 31 with value: 0.7584149537867292.\n",
            "[I 2025-03-18 08:13:19,974] Trial 36 finished with value: 0.7583838037727116 and parameters: {'w_xgb': 0.11401495240811467, 'w_lgb': 0.5932638457211519}. Best is trial 31 with value: 0.7584149537867292.\n",
            "[I 2025-03-18 08:13:19,994] Trial 37 finished with value: 0.7583793537707093 and parameters: {'w_xgb': 0.2679590930742043, 'w_lgb': 0.5923512196477299}. Best is trial 31 with value: 0.7584149537867292.\n",
            "[I 2025-03-18 08:13:20,008] Trial 38 finished with value: 0.7569064031078814 and parameters: {'w_xgb': 0.22159015934346654, 'w_lgb': 0.20090033065751833}. Best is trial 31 with value: 0.7584149537867292.\n",
            "[I 2025-03-18 08:13:20,026] Trial 39 finished with value: 0.7582325037046268 and parameters: {'w_xgb': 0.16358225920772806, 'w_lgb': 0.5155514468872401}. Best is trial 31 with value: 0.7584149537867292.\n",
            "[I 2025-03-18 08:13:20,041] Trial 40 finished with value: 0.7579688410859785 and parameters: {'w_xgb': 0.2515030588764871, 'w_lgb': 0.3987518774200247}. Best is trial 31 with value: 0.7584149537867292.\n",
            "[I 2025-03-18 08:13:20,057] Trial 41 finished with value: 0.7583927037767167 and parameters: {'w_xgb': 0.10729416274574335, 'w_lgb': 0.5829247616216735}. Best is trial 31 with value: 0.7584149537867292.\n",
            "[I 2025-03-18 08:13:20,076] Trial 42 finished with value: 0.7584027162812224 and parameters: {'w_xgb': 0.1241813640259163, 'w_lgb': 0.5792151214935625}. Best is trial 31 with value: 0.7584149537867292.\n",
            "[I 2025-03-18 08:13:20,092] Trial 43 finished with value: 0.7583604412621987 and parameters: {'w_xgb': 0.12692946325930227, 'w_lgb': 0.5704426030868701}. Best is trial 31 with value: 0.7584149537867292.\n",
            "[I 2025-03-18 08:13:20,110] Trial 44 finished with value: 0.7582814537266542 and parameters: {'w_xgb': 0.14011186063926173, 'w_lgb': 0.5118880288181982}. Best is trial 31 with value: 0.7584149537867292.\n",
            "[I 2025-03-18 08:13:20,127] Trial 45 finished with value: 0.7583971537787193 and parameters: {'w_xgb': 0.16771637094214575, 'w_lgb': 0.5751582053542343}. Best is trial 31 with value: 0.7584149537867292.\n",
            "[I 2025-03-18 08:13:20,142] Trial 46 finished with value: 0.7581535161690823 and parameters: {'w_xgb': 0.17712586923406232, 'w_lgb': 0.4714313900106015}. Best is trial 31 with value: 0.7584149537867292.\n",
            "[I 2025-03-18 08:13:20,157] Trial 47 finished with value: 0.7573258157966172 and parameters: {'w_xgb': 0.14198731658351502, 'w_lgb': 0.283951617719602}. Best is trial 31 with value: 0.7584149537867292.\n",
            "[I 2025-03-18 08:13:20,172] Trial 48 finished with value: 0.7560342027153912 and parameters: {'w_xgb': 0.21424298106651193, 'w_lgb': 0.10002841591370698}. Best is trial 31 with value: 0.7584149537867292.\n",
            "[I 2025-03-18 08:13:20,187] Trial 49 finished with value: 0.7583960412782186 and parameters: {'w_xgb': 0.16566759878141826, 'w_lgb': 0.5757617281562692}. Best is trial 31 with value: 0.7584149537867292.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "최적 가중치: {'w_xgb': 0.23263038132620692, 'w_lgb': 0.5720780559269026}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "\n",
        "# 최적 가중치 적용\n",
        "w_xgb = 0.187\n",
        "w_lgb = 0.6\n",
        "w_cat = 1 - (w_xgb + w_lgb)\n",
        "\n",
        "# 최적 파라미터 기반 모델 생성\n",
        "xgb_model = XGBClassifier(**best_xgb_params, random_state=42, eval_metric=\"logloss\")\n",
        "lgb_model = LGBMClassifier(**best_lgb_params, random_state=42, verbose=-1)\n",
        "cat_model = CatBoostClassifier(**best_cat_params, random_state=42, verbose=0)\n",
        "\n",
        "# 모델 학습\n",
        "xgb_model.fit(X_train, y_train)\n",
        "lgb_model.fit(X_train, y_train)\n",
        "cat_model.fit(X_train, y_train)\n",
        "\n",
        "# 검증 데이터 예측 (확률 값 추출)\n",
        "y_valid_xgb = xgb_model.predict_proba(X_valid)[:, 1]\n",
        "y_valid_lgb = lgb_model.predict_proba(X_valid)[:, 1]\n",
        "y_valid_cat = cat_model.predict_proba(X_valid)[:, 1]\n",
        "\n",
        "# 📌 최적 가중치 적용한 Soft Voting (가중 평균)\n",
        "final_valid_pred = (w_xgb * y_valid_xgb) + (w_lgb * y_valid_lgb) + (w_cat * y_valid_cat)\n",
        "\n",
        "# 성능 평가\n",
        "roc_auc_ensemble = roc_auc_score(y_valid, final_valid_pred)\n",
        "print(f\"최적 가중치 적용 후 앙상블 모델 ROC-AUC: {roc_auc_ensemble:.6f}\")\n",
        "\n",
        "# 테스트 데이터 예측\n",
        "y_test_xgb = xgb_model.predict_proba(X_test_scaled)[:, 1]\n",
        "y_test_lgb = lgb_model.predict_proba(X_test_scaled)[:, 1]\n",
        "y_test_cat = cat_model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "# 📌 최적 가중치 적용한 최종 테스트 데이터 예측\n",
        "y_test_final = (w_xgb * y_test_xgb) + (w_lgb * y_test_lgb) + (w_cat * y_test_cat)\n",
        "\n",
        "# 제출 파일 생성\n",
        "submission = pd.DataFrame({\"UID\": test_UID, \"채무 불이행 확률\": y_test_final})\n",
        "submission.to_csv(\"submission.csv\", index=False)\n",
        "\n",
        "print(\"✅ 최적 가중치 적용한 앙상블 예측 완료! 결과가 submission.csv에 저장되었습니다.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gUqS0B5tLIA",
        "outputId": "4d0d1c4b-cd09-4026-c713-09ce435d35aa"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "최적 가중치 적용 후 앙상블 모델 ROC-AUC: 0.758504\n",
            "✅ 최적 가중치 적용한 앙상블 예측 완료! 결과가 submission.csv에 저장되었습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "def objective(trial):\n",
        "    w_xgb = trial.suggest_float(\"w_xgb\", 0.05, 0.85, step=0.05)  # 최대값 증가\n",
        "    w_lgb = trial.suggest_float(\"w_lgb\", 0.05, 0.85, step=0.05)\n",
        "\n",
        "    if w_xgb + w_lgb >= 1.0:  # 1.0 초과 방지\n",
        "        return float('-inf')\n",
        "\n",
        "    w_cat = 1.0 - (w_xgb + w_lgb)\n",
        "\n",
        "    final_pred = (w_xgb * y_valid_xgb) + (w_lgb * y_valid_lgb) + (w_cat * y_valid_cat)\n",
        "    return roc_auc_score(y_valid, final_pred)\n",
        "\n",
        "\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=200)\n",
        "best_weights = study.best_params\n",
        "print(\"최적 가중치:\", best_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U52kSjmlSZjH",
        "outputId": "6fa7b63f-bb79-44ef-d01b-cbf7d89fe5c4"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-03-18 08:38:34,959] A new study created in memory with name: no-name-97b48d48-678a-407d-860b-308f3dad7d9c\n",
            "[I 2025-03-18 08:38:34,968] Trial 0 finished with value: 0.7578731660429247 and parameters: {'w_xgb': 0.1, 'w_lgb': 0.4}. Best is trial 0 with value: 0.7578731660429247.\n",
            "[I 2025-03-18 08:38:34,976] Trial 1 finished with value: 0.7583192787436754 and parameters: {'w_xgb': 0.15000000000000002, 'w_lgb': 0.55}. Best is trial 1 with value: 0.7583192787436754.\n",
            "[I 2025-03-18 08:38:34,983] Trial 2 finished with value: 0.756307877838545 and parameters: {'w_xgb': 0.15000000000000002, 'w_lgb': 0.15000000000000002}. Best is trial 1 with value: 0.7583192787436754.\n",
            "[I 2025-03-18 08:38:34,987] Trial 3 finished with value: -inf and parameters: {'w_xgb': 0.5, 'w_lgb': 0.6500000000000001}. Best is trial 1 with value: 0.7583192787436754.\n",
            "[I 2025-03-18 08:38:34,990] Trial 4 finished with value: -inf and parameters: {'w_xgb': 0.85, 'w_lgb': 0.6000000000000001}. Best is trial 1 with value: 0.7583192787436754.\n",
            "[I 2025-03-18 08:38:34,997] Trial 5 finished with value: 0.7568596780868551 and parameters: {'w_xgb': 0.2, 'w_lgb': 0.2}. Best is trial 1 with value: 0.7583192787436754.\n",
            "[I 2025-03-18 08:38:35,000] Trial 6 finished with value: -inf and parameters: {'w_xgb': 0.7000000000000001, 'w_lgb': 0.6000000000000001}. Best is trial 1 with value: 0.7583192787436754.\n",
            "[I 2025-03-18 08:38:35,007] Trial 7 finished with value: 0.7584550038047516 and parameters: {'w_xgb': 0.15000000000000002, 'w_lgb': 0.6000000000000001}. Best is trial 7 with value: 0.7584550038047516.\n",
            "[I 2025-03-18 08:38:35,011] Trial 8 finished with value: -inf and parameters: {'w_xgb': 0.25, 'w_lgb': 0.7500000000000001}. Best is trial 7 with value: 0.7584550038047516.\n",
            "[I 2025-03-18 08:38:35,014] Trial 9 finished with value: -inf and parameters: {'w_xgb': 0.2, 'w_lgb': 0.8}. Best is trial 7 with value: 0.7584550038047516.\n",
            "[I 2025-03-18 08:38:35,037] Trial 10 finished with value: 0.7578920785514354 and parameters: {'w_xgb': 0.4, 'w_lgb': 0.35000000000000003}. Best is trial 7 with value: 0.7584550038047516.\n",
            "[I 2025-03-18 08:38:35,059] Trial 11 finished with value: 0.7580834286375429 and parameters: {'w_xgb': 0.05, 'w_lgb': 0.5}. Best is trial 7 with value: 0.7584550038047516.\n",
            "[I 2025-03-18 08:38:35,081] Trial 12 finished with value: 0.7582925787316604 and parameters: {'w_xgb': 0.45, 'w_lgb': 0.5}. Best is trial 7 with value: 0.7584550038047516.\n",
            "[I 2025-03-18 08:38:35,106] Trial 13 finished with value: 0.7575650034042515 and parameters: {'w_xgb': 0.35000000000000003, 'w_lgb': 0.3}. Best is trial 7 with value: 0.7584550038047516.\n",
            "[I 2025-03-18 08:38:35,126] Trial 14 finished with value: -inf and parameters: {'w_xgb': 0.6000000000000001, 'w_lgb': 0.7000000000000001}. Best is trial 7 with value: 0.7584550038047516.\n",
            "[I 2025-03-18 08:38:35,179] Trial 15 finished with value: 0.7556581775461799 and parameters: {'w_xgb': 0.3, 'w_lgb': 0.05}. Best is trial 7 with value: 0.7584550038047516.\n",
            "[I 2025-03-18 08:38:35,234] Trial 16 finished with value: 0.7580834286375429 and parameters: {'w_xgb': 0.05, 'w_lgb': 0.5}. Best is trial 7 with value: 0.7584550038047516.\n",
            "[I 2025-03-18 08:38:35,270] Trial 17 finished with value: -inf and parameters: {'w_xgb': 0.55, 'w_lgb': 0.6000000000000001}. Best is trial 7 with value: 0.7584550038047516.\n",
            "[I 2025-03-18 08:38:35,340] Trial 18 finished with value: -inf and parameters: {'w_xgb': 0.3, 'w_lgb': 0.85}. Best is trial 7 with value: 0.7584550038047516.\n",
            "[I 2025-03-18 08:38:35,408] Trial 19 finished with value: 0.7580200161090074 and parameters: {'w_xgb': 0.15000000000000002, 'w_lgb': 0.45}. Best is trial 7 with value: 0.7584550038047516.\n",
            "[I 2025-03-18 08:38:35,446] Trial 20 finished with value: -inf and parameters: {'w_xgb': 0.6500000000000001, 'w_lgb': 0.7000000000000001}. Best is trial 7 with value: 0.7584550038047516.\n",
            "[I 2025-03-18 08:38:35,504] Trial 21 finished with value: 0.7582836787276555 and parameters: {'w_xgb': 0.4, 'w_lgb': 0.5}. Best is trial 7 with value: 0.7584550038047516.\n",
            "[I 2025-03-18 08:38:35,556] Trial 22 finished with value: -inf and parameters: {'w_xgb': 0.7500000000000001, 'w_lgb': 0.55}. Best is trial 7 with value: 0.7584550038047516.\n",
            "[I 2025-03-18 08:38:35,608] Trial 23 finished with value: 0.7580222411100085 and parameters: {'w_xgb': 0.45, 'w_lgb': 0.4}. Best is trial 7 with value: 0.7584550038047516.\n",
            "[I 2025-03-18 08:38:35,677] Trial 24 finished with value: 0.757507153378219 and parameters: {'w_xgb': 0.25, 'w_lgb': 0.3}. Best is trial 7 with value: 0.7584550038047516.\n",
            "[I 2025-03-18 08:38:35,729] Trial 25 finished with value: 0.7583192787436754 and parameters: {'w_xgb': 0.15000000000000002, 'w_lgb': 0.55}. Best is trial 7 with value: 0.7584550038047516.\n",
            "[I 2025-03-18 08:38:35,755] Trial 26 finished with value: 0.7585618038528118 and parameters: {'w_xgb': 0.1, 'w_lgb': 0.7000000000000001}. Best is trial 26 with value: 0.7585618038528118.\n",
            "[I 2025-03-18 08:38:35,782] Trial 27 finished with value: 0.7584883788197705 and parameters: {'w_xgb': 0.05, 'w_lgb': 0.8}. Best is trial 26 with value: 0.7585618038528118.\n",
            "[I 2025-03-18 08:38:35,833] Trial 28 finished with value: 0.7584616788077554 and parameters: {'w_xgb': 0.05, 'w_lgb': 0.85}. Best is trial 26 with value: 0.7585618038528118.\n",
            "[I 2025-03-18 08:38:35,899] Trial 29 finished with value: 0.7584616788077554 and parameters: {'w_xgb': 0.05, 'w_lgb': 0.85}. Best is trial 26 with value: 0.7585618038528118.\n",
            "[I 2025-03-18 08:38:35,951] Trial 30 finished with value: 0.7585462288458029 and parameters: {'w_xgb': 0.1, 'w_lgb': 0.7500000000000001}. Best is trial 26 with value: 0.7585618038528118.\n",
            "[I 2025-03-18 08:38:36,011] Trial 31 finished with value: 0.7585462288458029 and parameters: {'w_xgb': 0.1, 'w_lgb': 0.7500000000000001}. Best is trial 26 with value: 0.7585618038528118.\n",
            "[I 2025-03-18 08:38:36,068] Trial 32 finished with value: 0.7585462288458029 and parameters: {'w_xgb': 0.1, 'w_lgb': 0.7500000000000001}. Best is trial 26 with value: 0.7585618038528118.\n",
            "[I 2025-03-18 08:38:36,121] Trial 33 finished with value: 0.7585462288458029 and parameters: {'w_xgb': 0.1, 'w_lgb': 0.7500000000000001}. Best is trial 26 with value: 0.7585618038528118.\n",
            "[I 2025-03-18 08:38:36,170] Trial 34 finished with value: 0.7585618038528118 and parameters: {'w_xgb': 0.1, 'w_lgb': 0.7000000000000001}. Best is trial 26 with value: 0.7585618038528118.\n",
            "[I 2025-03-18 08:38:36,241] Trial 35 finished with value: 0.7586285538828492 and parameters: {'w_xgb': 0.2, 'w_lgb': 0.7000000000000001}. Best is trial 35 with value: 0.7586285538828492.\n",
            "[I 2025-03-18 08:38:36,304] Trial 36 finished with value: 0.758519528833788 and parameters: {'w_xgb': 0.25, 'w_lgb': 0.6500000000000001}. Best is trial 35 with value: 0.7586285538828492.\n",
            "[I 2025-03-18 08:38:36,349] Trial 37 finished with value: 0.7584972788237754 and parameters: {'w_xgb': 0.2, 'w_lgb': 0.6500000000000001}. Best is trial 35 with value: 0.7586285538828492.\n",
            "[I 2025-03-18 08:38:36,408] Trial 38 finished with value: 0.7586018538708342 and parameters: {'w_xgb': 0.15000000000000002, 'w_lgb': 0.7000000000000001}. Best is trial 35 with value: 0.7586285538828492.\n",
            "[I 2025-03-18 08:38:36,457] Trial 39 finished with value: 0.7586285538828492 and parameters: {'w_xgb': 0.2, 'w_lgb': 0.7000000000000001}. Best is trial 35 with value: 0.7586285538828492.\n",
            "[I 2025-03-18 08:38:36,540] Trial 40 finished with value: 0.7584972788237754 and parameters: {'w_xgb': 0.2, 'w_lgb': 0.6500000000000001}. Best is trial 35 with value: 0.7586285538828492.\n",
            "[I 2025-03-18 08:38:36,606] Trial 41 finished with value: 0.7586018538708342 and parameters: {'w_xgb': 0.15000000000000002, 'w_lgb': 0.7000000000000001}. Best is trial 35 with value: 0.7586285538828492.\n",
            "[I 2025-03-18 08:38:36,650] Trial 42 finished with value: -inf and parameters: {'w_xgb': 0.3, 'w_lgb': 0.8}. Best is trial 35 with value: 0.7586285538828492.\n",
            "[I 2025-03-18 08:38:36,679] Trial 43 finished with value: 0.7586018538708342 and parameters: {'w_xgb': 0.15000000000000002, 'w_lgb': 0.7000000000000001}. Best is trial 35 with value: 0.7586285538828492.\n",
            "[I 2025-03-18 08:38:36,707] Trial 44 finished with value: 0.7584550038047516 and parameters: {'w_xgb': 0.15000000000000002, 'w_lgb': 0.6000000000000001}. Best is trial 35 with value: 0.7586285538828492.\n",
            "[I 2025-03-18 08:38:36,736] Trial 45 finished with value: 0.7586051913723361 and parameters: {'w_xgb': 0.25, 'w_lgb': 0.7000000000000001}. Best is trial 35 with value: 0.7586285538828492.\n",
            "[I 2025-03-18 08:38:36,761] Trial 46 finished with value: -inf and parameters: {'w_xgb': 0.25, 'w_lgb': 0.8}. Best is trial 35 with value: 0.7586285538828492.\n",
            "[I 2025-03-18 08:38:36,789] Trial 47 finished with value: 0.7583081537386692 and parameters: {'w_xgb': 0.2, 'w_lgb': 0.55}. Best is trial 35 with value: 0.7586285538828492.\n",
            "[I 2025-03-18 08:38:36,812] Trial 48 finished with value: -inf and parameters: {'w_xgb': 0.35000000000000003, 'w_lgb': 0.6500000000000001}. Best is trial 35 with value: 0.7586285538828492.\n",
            "[I 2025-03-18 08:38:36,836] Trial 49 finished with value: -inf and parameters: {'w_xgb': 0.35000000000000003, 'w_lgb': 0.6500000000000001}. Best is trial 35 with value: 0.7586285538828492.\n",
            "[I 2025-03-18 08:38:36,860] Trial 50 finished with value: -inf and parameters: {'w_xgb': 0.25, 'w_lgb': 0.8}. Best is trial 35 with value: 0.7586285538828492.\n",
            "[I 2025-03-18 08:38:36,890] Trial 51 finished with value: 0.7586018538708342 and parameters: {'w_xgb': 0.15000000000000002, 'w_lgb': 0.7000000000000001}. Best is trial 35 with value: 0.7586285538828492.\n",
            "[I 2025-03-18 08:38:36,934] Trial 52 finished with value: 0.7586285538828492 and parameters: {'w_xgb': 0.2, 'w_lgb': 0.7000000000000001}. Best is trial 35 with value: 0.7586285538828492.\n",
            "[I 2025-03-18 08:38:36,970] Trial 53 finished with value: 0.7584483288017481 and parameters: {'w_xgb': 0.2, 'w_lgb': 0.6000000000000001}. Best is trial 35 with value: 0.7586285538828492.\n",
            "[I 2025-03-18 08:38:36,994] Trial 54 finished with value: -inf and parameters: {'w_xgb': 0.3, 'w_lgb': 0.7500000000000001}. Best is trial 35 with value: 0.7586285538828492.\n",
            "[I 2025-03-18 08:38:37,024] Trial 55 finished with value: 0.7586285538828492 and parameters: {'w_xgb': 0.2, 'w_lgb': 0.7000000000000001}. Best is trial 35 with value: 0.7586285538828492.\n",
            "[I 2025-03-18 08:38:37,052] Trial 56 finished with value: 0.758585166363325 and parameters: {'w_xgb': 0.3, 'w_lgb': 0.6500000000000001}. Best is trial 35 with value: 0.7586285538828492.\n",
            "[I 2025-03-18 08:38:37,080] Trial 57 finished with value: 0.7569397781229003 and parameters: {'w_xgb': 0.25, 'w_lgb': 0.2}. Best is trial 35 with value: 0.7586285538828492.\n",
            "[I 2025-03-18 08:38:37,108] Trial 58 finished with value: 0.7584483288017481 and parameters: {'w_xgb': 0.2, 'w_lgb': 0.6000000000000001}. Best is trial 35 with value: 0.7586285538828492.\n",
            "[I 2025-03-18 08:38:37,133] Trial 59 finished with value: -inf and parameters: {'w_xgb': 0.4, 'w_lgb': 0.7500000000000001}. Best is trial 35 with value: 0.7586285538828492.\n",
            "[I 2025-03-18 08:38:37,163] Trial 60 finished with value: 0.7583081537386692 and parameters: {'w_xgb': 0.2, 'w_lgb': 0.55}. Best is trial 35 with value: 0.7586285538828492.\n",
            "[I 2025-03-18 08:38:37,189] Trial 61 finished with value: -inf and parameters: {'w_xgb': 0.85, 'w_lgb': 0.7000000000000001}. Best is trial 35 with value: 0.7586285538828492.\n",
            "[I 2025-03-18 08:38:37,218] Trial 62 finished with value: 0.7586018538708342 and parameters: {'w_xgb': 0.15000000000000002, 'w_lgb': 0.7000000000000001}. Best is trial 35 with value: 0.7586285538828492.\n",
            "[I 2025-03-18 08:38:37,248] Trial 63 finished with value: 0.7555736275081323 and parameters: {'w_xgb': 0.25, 'w_lgb': 0.05}. Best is trial 35 with value: 0.7586285538828492.\n",
            "[I 2025-03-18 08:38:37,273] Trial 64 finished with value: -inf and parameters: {'w_xgb': 0.5, 'w_lgb': 0.6000000000000001}. Best is trial 35 with value: 0.7586285538828492.\n",
            "[I 2025-03-18 08:38:37,303] Trial 65 finished with value: 0.7586018538708342 and parameters: {'w_xgb': 0.15000000000000002, 'w_lgb': 0.8}. Best is trial 35 with value: 0.7586285538828492.\n",
            "[I 2025-03-18 08:38:37,332] Trial 66 finished with value: 0.7584972788237754 and parameters: {'w_xgb': 0.2, 'w_lgb': 0.6500000000000001}. Best is trial 35 with value: 0.7586285538828492.\n",
            "[I 2025-03-18 08:38:37,381] Trial 67 finished with value: 0.7586585913963662 and parameters: {'w_xgb': 0.15000000000000002, 'w_lgb': 0.7500000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:37,411] Trial 68 finished with value: -inf and parameters: {'w_xgb': 0.2, 'w_lgb': 0.85}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:37,445] Trial 69 finished with value: -inf and parameters: {'w_xgb': 0.3, 'w_lgb': 0.7500000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:37,481] Trial 70 finished with value: 0.7586051913723361 and parameters: {'w_xgb': 0.25, 'w_lgb': 0.7000000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:37,521] Trial 71 finished with value: 0.7586051913723361 and parameters: {'w_xgb': 0.25, 'w_lgb': 0.7000000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:37,569] Trial 72 finished with value: -inf and parameters: {'w_xgb': 0.25, 'w_lgb': 0.7500000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:37,611] Trial 73 finished with value: -inf and parameters: {'w_xgb': 0.35000000000000003, 'w_lgb': 0.7500000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:37,642] Trial 74 finished with value: -inf and parameters: {'w_xgb': 0.3, 'w_lgb': 0.8}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:37,672] Trial 75 finished with value: 0.758519528833788 and parameters: {'w_xgb': 0.25, 'w_lgb': 0.6500000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:37,702] Trial 76 finished with value: 0.7586285538828492 and parameters: {'w_xgb': 0.2, 'w_lgb': 0.7000000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:37,754] Trial 77 finished with value: 0.7586285538828492 and parameters: {'w_xgb': 0.2, 'w_lgb': 0.7000000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:37,782] Trial 78 finished with value: -inf and parameters: {'w_xgb': 0.8, 'w_lgb': 0.6000000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:37,816] Trial 79 finished with value: 0.7557683150957419 and parameters: {'w_xgb': 0.1, 'w_lgb': 0.1}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:37,848] Trial 80 finished with value: 0.7581001161450522 and parameters: {'w_xgb': 0.2, 'w_lgb': 0.45}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:37,880] Trial 81 finished with value: 0.7585618038528118 and parameters: {'w_xgb': 0.1, 'w_lgb': 0.7000000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:37,911] Trial 82 finished with value: 0.7584972788237754 and parameters: {'w_xgb': 0.2, 'w_lgb': 0.6500000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:37,944] Trial 83 finished with value: 0.7586585913963662 and parameters: {'w_xgb': 0.15000000000000002, 'w_lgb': 0.7500000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:38,008] Trial 84 finished with value: 0.7586585913963662 and parameters: {'w_xgb': 0.15000000000000002, 'w_lgb': 0.7500000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:38,042] Trial 85 finished with value: 0.7584883788197705 and parameters: {'w_xgb': 0.05, 'w_lgb': 0.8}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:38,074] Trial 86 finished with value: 0.7586585913963662 and parameters: {'w_xgb': 0.15000000000000002, 'w_lgb': 0.7500000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:38,101] Trial 87 finished with value: -inf and parameters: {'w_xgb': 0.15000000000000002, 'w_lgb': 0.85}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:38,134] Trial 88 finished with value: 0.7585462288458029 and parameters: {'w_xgb': 0.1, 'w_lgb': 0.7500000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:38,166] Trial 89 finished with value: 0.7585462288458029 and parameters: {'w_xgb': 0.1, 'w_lgb': 0.7500000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:38,201] Trial 90 finished with value: 0.7586018538708342 and parameters: {'w_xgb': 0.15000000000000002, 'w_lgb': 0.8}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:38,267] Trial 91 finished with value: 0.7586585913963662 and parameters: {'w_xgb': 0.15000000000000002, 'w_lgb': 0.7500000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:38,308] Trial 92 finished with value: 0.7586585913963662 and parameters: {'w_xgb': 0.15000000000000002, 'w_lgb': 0.7500000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:38,341] Trial 93 finished with value: 0.7586585913963662 and parameters: {'w_xgb': 0.15000000000000002, 'w_lgb': 0.7500000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:38,376] Trial 94 finished with value: 0.7585618038528118 and parameters: {'w_xgb': 0.05, 'w_lgb': 0.7500000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:38,414] Trial 95 finished with value: 0.7586018538708342 and parameters: {'w_xgb': 0.15000000000000002, 'w_lgb': 0.8}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:38,446] Trial 96 finished with value: 0.7585173038327866 and parameters: {'w_xgb': 0.1, 'w_lgb': 0.85}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:38,477] Trial 97 finished with value: 0.7586585913963662 and parameters: {'w_xgb': 0.15000000000000002, 'w_lgb': 0.7500000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:38,511] Trial 98 finished with value: 0.7586585913963662 and parameters: {'w_xgb': 0.15000000000000002, 'w_lgb': 0.7500000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:38,545] Trial 99 finished with value: 0.7586585913963662 and parameters: {'w_xgb': 0.15000000000000002, 'w_lgb': 0.7500000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:38,578] Trial 100 finished with value: 0.7585784913603212 and parameters: {'w_xgb': 0.1, 'w_lgb': 0.8}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:38,610] Trial 101 finished with value: 0.7586585913963662 and parameters: {'w_xgb': 0.15000000000000002, 'w_lgb': 0.7500000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:38,655] Trial 102 finished with value: 0.7586585913963662 and parameters: {'w_xgb': 0.15000000000000002, 'w_lgb': 0.7500000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:38,706] Trial 103 finished with value: 0.7586585913963662 and parameters: {'w_xgb': 0.15000000000000002, 'w_lgb': 0.7500000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:38,744] Trial 104 finished with value: 0.7585784913603212 and parameters: {'w_xgb': 0.1, 'w_lgb': 0.8}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:38,784] Trial 105 finished with value: 0.7586585913963662 and parameters: {'w_xgb': 0.15000000000000002, 'w_lgb': 0.7500000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:38,817] Trial 106 finished with value: 0.7586018538708342 and parameters: {'w_xgb': 0.15000000000000002, 'w_lgb': 0.8}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:38,849] Trial 107 finished with value: 0.7584616788077554 and parameters: {'w_xgb': 0.05, 'w_lgb': 0.85}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:38,881] Trial 108 finished with value: 0.7585462288458029 and parameters: {'w_xgb': 0.1, 'w_lgb': 0.7500000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:38,914] Trial 109 finished with value: 0.7586585913963662 and parameters: {'w_xgb': 0.15000000000000002, 'w_lgb': 0.7500000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:38,949] Trial 110 finished with value: 0.7573936783271553 and parameters: {'w_xgb': 0.05, 'w_lgb': 0.3}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:38,983] Trial 111 finished with value: 0.7586585913963662 and parameters: {'w_xgb': 0.15000000000000002, 'w_lgb': 0.7500000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:39,030] Trial 112 finished with value: 0.7585462288458029 and parameters: {'w_xgb': 0.1, 'w_lgb': 0.7500000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:39,062] Trial 113 finished with value: 0.7586018538708342 and parameters: {'w_xgb': 0.15000000000000002, 'w_lgb': 0.8}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:39,095] Trial 114 finished with value: 0.7586585913963662 and parameters: {'w_xgb': 0.15000000000000002, 'w_lgb': 0.7500000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:39,125] Trial 115 finished with value: -inf and parameters: {'w_xgb': 0.6000000000000001, 'w_lgb': 0.8}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:39,176] Trial 116 finished with value: 0.7585462288458029 and parameters: {'w_xgb': 0.1, 'w_lgb': 0.7500000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:39,208] Trial 117 finished with value: -inf and parameters: {'w_xgb': 0.15000000000000002, 'w_lgb': 0.85}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:39,240] Trial 118 finished with value: -inf and parameters: {'w_xgb': 0.2, 'w_lgb': 0.8}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:39,272] Trial 119 finished with value: 0.7586018538708342 and parameters: {'w_xgb': 0.15000000000000002, 'w_lgb': 0.7000000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:39,305] Trial 120 finished with value: 0.7585462288458029 and parameters: {'w_xgb': 0.1, 'w_lgb': 0.7500000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:39,345] Trial 121 finished with value: 0.7586585913963662 and parameters: {'w_xgb': 0.15000000000000002, 'w_lgb': 0.7500000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:39,378] Trial 122 finished with value: 0.7586140913763412 and parameters: {'w_xgb': 0.2, 'w_lgb': 0.7500000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:39,416] Trial 123 finished with value: 0.7586018538708342 and parameters: {'w_xgb': 0.15000000000000002, 'w_lgb': 0.8}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:39,446] Trial 124 finished with value: 0.7586018538708342 and parameters: {'w_xgb': 0.15000000000000002, 'w_lgb': 0.7000000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:39,476] Trial 125 finished with value: 0.7585462288458029 and parameters: {'w_xgb': 0.1, 'w_lgb': 0.7500000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:39,505] Trial 126 finished with value: -inf and parameters: {'w_xgb': 0.2, 'w_lgb': 0.8}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:39,560] Trial 127 finished with value: 0.7586585913963662 and parameters: {'w_xgb': 0.15000000000000002, 'w_lgb': 0.7500000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:39,596] Trial 128 finished with value: 0.7586285538828492 and parameters: {'w_xgb': 0.2, 'w_lgb': 0.7000000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:39,624] Trial 129 finished with value: -inf and parameters: {'w_xgb': 0.7000000000000001, 'w_lgb': 0.7500000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:39,661] Trial 130 finished with value: 0.7585618038528118 and parameters: {'w_xgb': 0.1, 'w_lgb': 0.7000000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:39,692] Trial 131 finished with value: 0.7586585913963662 and parameters: {'w_xgb': 0.15000000000000002, 'w_lgb': 0.7500000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:39,723] Trial 132 finished with value: 0.7586018538708342 and parameters: {'w_xgb': 0.15000000000000002, 'w_lgb': 0.8}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:39,757] Trial 133 finished with value: 0.7586585913963662 and parameters: {'w_xgb': 0.15000000000000002, 'w_lgb': 0.7500000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:39,787] Trial 134 finished with value: 0.7586285538828492 and parameters: {'w_xgb': 0.2, 'w_lgb': 0.7000000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:39,819] Trial 135 finished with value: 0.7585784913603212 and parameters: {'w_xgb': 0.1, 'w_lgb': 0.8}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:39,850] Trial 136 finished with value: 0.7586585913963662 and parameters: {'w_xgb': 0.15000000000000002, 'w_lgb': 0.7500000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:39,885] Trial 137 finished with value: 0.7586585913963662 and parameters: {'w_xgb': 0.15000000000000002, 'w_lgb': 0.7500000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:39,917] Trial 138 finished with value: 0.7577085159688322 and parameters: {'w_xgb': 0.2, 'w_lgb': 0.35000000000000003}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:39,950] Trial 139 finished with value: 0.7585784913603212 and parameters: {'w_xgb': 0.1, 'w_lgb': 0.8}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:39,983] Trial 140 finished with value: 0.7586018538708342 and parameters: {'w_xgb': 0.15000000000000002, 'w_lgb': 0.7000000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:40,016] Trial 141 finished with value: 0.7586585913963662 and parameters: {'w_xgb': 0.15000000000000002, 'w_lgb': 0.7500000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:40,069] Trial 142 finished with value: 0.7586585913963662 and parameters: {'w_xgb': 0.15000000000000002, 'w_lgb': 0.7500000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:40,112] Trial 143 finished with value: 0.7586140913763412 and parameters: {'w_xgb': 0.2, 'w_lgb': 0.7500000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:40,148] Trial 144 finished with value: 0.7586018538708342 and parameters: {'w_xgb': 0.15000000000000002, 'w_lgb': 0.8}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:40,185] Trial 145 finished with value: 0.7585462288458029 and parameters: {'w_xgb': 0.1, 'w_lgb': 0.7500000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:40,221] Trial 146 finished with value: 0.7584972788237754 and parameters: {'w_xgb': 0.2, 'w_lgb': 0.6500000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:40,256] Trial 147 finished with value: 0.7586018538708342 and parameters: {'w_xgb': 0.15000000000000002, 'w_lgb': 0.7000000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:40,295] Trial 148 finished with value: 0.7585618038528118 and parameters: {'w_xgb': 0.1, 'w_lgb': 0.7000000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:40,338] Trial 149 finished with value: 0.7584883788197705 and parameters: {'w_xgb': 0.05, 'w_lgb': 0.8}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:40,374] Trial 150 finished with value: 0.7586585913963662 and parameters: {'w_xgb': 0.15000000000000002, 'w_lgb': 0.7500000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:40,415] Trial 151 finished with value: 0.7586585913963662 and parameters: {'w_xgb': 0.15000000000000002, 'w_lgb': 0.7500000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:40,456] Trial 152 finished with value: 0.7586585913963662 and parameters: {'w_xgb': 0.15000000000000002, 'w_lgb': 0.7500000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:40,513] Trial 153 finished with value: 0.7585462288458029 and parameters: {'w_xgb': 0.1, 'w_lgb': 0.7500000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:40,562] Trial 154 finished with value: 0.7586140913763412 and parameters: {'w_xgb': 0.2, 'w_lgb': 0.7500000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:40,599] Trial 155 finished with value: 0.7586018538708342 and parameters: {'w_xgb': 0.15000000000000002, 'w_lgb': 0.7000000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:40,637] Trial 156 finished with value: -inf and parameters: {'w_xgb': 0.2, 'w_lgb': 0.8}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:40,691] Trial 157 finished with value: 0.7586585913963662 and parameters: {'w_xgb': 0.15000000000000002, 'w_lgb': 0.7500000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:40,730] Trial 158 finished with value: 0.7586018538708342 and parameters: {'w_xgb': 0.15000000000000002, 'w_lgb': 0.7000000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:40,767] Trial 159 finished with value: 0.7585784913603212 and parameters: {'w_xgb': 0.1, 'w_lgb': 0.8}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:40,804] Trial 160 finished with value: 0.7585462288458029 and parameters: {'w_xgb': 0.1, 'w_lgb': 0.7500000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:40,843] Trial 161 finished with value: 0.7586585913963662 and parameters: {'w_xgb': 0.15000000000000002, 'w_lgb': 0.7500000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:40,880] Trial 162 finished with value: 0.7586585913963662 and parameters: {'w_xgb': 0.15000000000000002, 'w_lgb': 0.7500000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:40,923] Trial 163 finished with value: 0.7586140913763412 and parameters: {'w_xgb': 0.2, 'w_lgb': 0.7500000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:40,961] Trial 164 finished with value: 0.7586018538708342 and parameters: {'w_xgb': 0.15000000000000002, 'w_lgb': 0.8}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:40,999] Trial 165 finished with value: 0.7586018538708342 and parameters: {'w_xgb': 0.15000000000000002, 'w_lgb': 0.7000000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:41,036] Trial 166 finished with value: -inf and parameters: {'w_xgb': 0.45, 'w_lgb': 0.7500000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:41,078] Trial 167 finished with value: 0.7586585913963662 and parameters: {'w_xgb': 0.15000000000000002, 'w_lgb': 0.7500000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:41,115] Trial 168 finished with value: -inf and parameters: {'w_xgb': 0.2, 'w_lgb': 0.8}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:41,154] Trial 169 finished with value: 0.7585462288458029 and parameters: {'w_xgb': 0.1, 'w_lgb': 0.7500000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:41,190] Trial 170 finished with value: 0.7586018538708342 and parameters: {'w_xgb': 0.15000000000000002, 'w_lgb': 0.7000000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:41,229] Trial 171 finished with value: 0.7586585913963662 and parameters: {'w_xgb': 0.15000000000000002, 'w_lgb': 0.7500000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:41,268] Trial 172 finished with value: 0.7586140913763412 and parameters: {'w_xgb': 0.2, 'w_lgb': 0.7500000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:41,305] Trial 173 finished with value: 0.7586018538708342 and parameters: {'w_xgb': 0.15000000000000002, 'w_lgb': 0.7000000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:41,343] Trial 174 finished with value: 0.7568051655623244 and parameters: {'w_xgb': 0.15000000000000002, 'w_lgb': 0.2}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:41,385] Trial 175 finished with value: 0.7585462288458029 and parameters: {'w_xgb': 0.1, 'w_lgb': 0.7500000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:41,430] Trial 176 finished with value: -inf and parameters: {'w_xgb': 0.5, 'w_lgb': 0.8}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:41,502] Trial 177 finished with value: 0.7585462288458029 and parameters: {'w_xgb': 0.1, 'w_lgb': 0.7500000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:41,543] Trial 178 finished with value: 0.7586018538708342 and parameters: {'w_xgb': 0.15000000000000002, 'w_lgb': 0.7000000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:41,588] Trial 179 finished with value: 0.7586140913763412 and parameters: {'w_xgb': 0.2, 'w_lgb': 0.7500000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:41,627] Trial 180 finished with value: 0.7586018538708342 and parameters: {'w_xgb': 0.15000000000000002, 'w_lgb': 0.8}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:41,665] Trial 181 finished with value: 0.7586585913963662 and parameters: {'w_xgb': 0.15000000000000002, 'w_lgb': 0.7500000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:41,703] Trial 182 finished with value: 0.7586585913963662 and parameters: {'w_xgb': 0.15000000000000002, 'w_lgb': 0.7500000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:41,756] Trial 183 finished with value: 0.7586585913963662 and parameters: {'w_xgb': 0.15000000000000002, 'w_lgb': 0.7500000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:41,827] Trial 184 finished with value: 0.7586140913763412 and parameters: {'w_xgb': 0.2, 'w_lgb': 0.7500000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:41,936] Trial 185 finished with value: 0.7585784913603212 and parameters: {'w_xgb': 0.1, 'w_lgb': 0.8}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:42,038] Trial 186 finished with value: 0.7586018538708342 and parameters: {'w_xgb': 0.15000000000000002, 'w_lgb': 0.7000000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:42,125] Trial 187 finished with value: 0.7586585913963662 and parameters: {'w_xgb': 0.15000000000000002, 'w_lgb': 0.7500000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:42,184] Trial 188 finished with value: 0.7586018538708342 and parameters: {'w_xgb': 0.15000000000000002, 'w_lgb': 0.8}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:42,224] Trial 189 finished with value: 0.7586140913763412 and parameters: {'w_xgb': 0.2, 'w_lgb': 0.7500000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:42,264] Trial 190 finished with value: 0.7585618038528118 and parameters: {'w_xgb': 0.1, 'w_lgb': 0.7000000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:42,297] Trial 191 finished with value: 0.7586585913963662 and parameters: {'w_xgb': 0.15000000000000002, 'w_lgb': 0.7500000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:42,320] Trial 192 finished with value: 0.7586585913963662 and parameters: {'w_xgb': 0.15000000000000002, 'w_lgb': 0.7500000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:42,344] Trial 193 finished with value: 0.7586140913763412 and parameters: {'w_xgb': 0.2, 'w_lgb': 0.7500000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:42,368] Trial 194 finished with value: 0.7586585913963662 and parameters: {'w_xgb': 0.15000000000000002, 'w_lgb': 0.7500000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:42,391] Trial 195 finished with value: 0.7586018538708342 and parameters: {'w_xgb': 0.15000000000000002, 'w_lgb': 0.8}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:42,416] Trial 196 finished with value: 0.7585462288458029 and parameters: {'w_xgb': 0.1, 'w_lgb': 0.7500000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:42,442] Trial 197 finished with value: 0.7586018538708342 and parameters: {'w_xgb': 0.15000000000000002, 'w_lgb': 0.7000000000000001}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:42,462] Trial 198 finished with value: -inf and parameters: {'w_xgb': 0.2, 'w_lgb': 0.8}. Best is trial 67 with value: 0.7586585913963662.\n",
            "[I 2025-03-18 08:38:42,485] Trial 199 finished with value: 0.7586018538708342 and parameters: {'w_xgb': 0.15000000000000002, 'w_lgb': 0.7000000000000001}. Best is trial 67 with value: 0.7586585913963662.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "최적 가중치: {'w_xgb': 0.15000000000000002, 'w_lgb': 0.7500000000000001}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "\n",
        "# ✅ Optuna에서 찾은 최적 가중치 적용\n",
        "w_xgb = 0.15\n",
        "w_lgb = 0.75\n",
        "w_cat = 1.0 - (w_xgb + w_lgb)  # w_cat = 0.10\n",
        "\n",
        "# 최적 파라미터 기반 모델 생성\n",
        "xgb_model = XGBClassifier(**best_xgb_params, random_state=42, eval_metric=\"logloss\")\n",
        "lgb_model = LGBMClassifier(**best_lgb_params, random_state=42, verbose=-1)\n",
        "cat_model = CatBoostClassifier(**best_cat_params, random_state=42, verbose=0)\n",
        "\n",
        "# 모델 학습\n",
        "xgb_model.fit(X_train, y_train)\n",
        "lgb_model.fit(X_train, y_train)\n",
        "cat_model.fit(X_train, y_train)\n",
        "\n",
        "# 검증 데이터 예측 (확률 값 추출)\n",
        "y_valid_xgb = xgb_model.predict_proba(X_valid)[:, 1]\n",
        "y_valid_lgb = lgb_model.predict_proba(X_valid)[:, 1]\n",
        "y_valid_cat = cat_model.predict_proba(X_valid)[:, 1]\n",
        "\n",
        "# ✅ 최적 가중치 적용한 Soft Voting (가중 평균)\n",
        "final_valid_pred = (w_xgb * y_valid_xgb) + (w_lgb * y_valid_lgb) + (w_cat * y_valid_cat)\n",
        "\n",
        "# 성능 평가\n",
        "roc_auc_ensemble = roc_auc_score(y_valid, final_valid_pred)\n",
        "print(f\"🔥 최적 가중치 적용 후 앙상블 모델 ROC-AUC: {roc_auc_ensemble:.6f}\")\n",
        "\n",
        "# ✅ 테스트 데이터 예측\n",
        "y_test_xgb = xgb_model.predict_proba(X_test_scaled)[:, 1]\n",
        "y_test_lgb = lgb_model.predict_proba(X_test_scaled)[:, 1]\n",
        "y_test_cat = cat_model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "# ✅ 최적 가중치 적용한 최종 테스트 데이터 예측\n",
        "y_test_final = (w_xgb * y_test_xgb) + (w_lgb * y_test_lgb) + (w_cat * y_test_cat)\n",
        "\n",
        "# 제출 파일 생성\n",
        "submission = pd.DataFrame({\"UID\": test_UID, \"채무 불이행 확률\": y_test_final})\n",
        "submission.to_csv(\"submission.csv\", index=False)\n",
        "\n",
        "print(\"✅ 최적 가중치 적용한 앙상블 예측 완료! 결과가 submission.csv에 저장되었습니다.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJ8hKVwhZ5GY",
        "outputId": "f96984e0-82da-4138-b20a-7b33dedc0b87"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔥 최적 가중치 적용 후 앙상블 모델 ROC-AUC: 0.758659\n",
            "✅ 최적 가중치 적용한 앙상블 예측 완료! 결과가 submission.csv에 저장되었습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import numpy as np\n",
        "\n",
        "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# 메타 특징 저장\n",
        "train_meta_features = np.zeros((X_train.shape[0], 3))\n",
        "test_meta_features = np.zeros((X_test_scaled.shape[0], 3))\n",
        "\n",
        "models = [\n",
        "    (\"xgb\", XGBClassifier(**best_xgb_params, random_state=42)),\n",
        "    (\"lgb\", LGBMClassifier(**best_lgb_params, random_state=42)),\n",
        "    (\"cat\", CatBoostClassifier(**best_cat_params, random_state=42, verbose=0))\n",
        "]\n",
        "\n",
        "# 각 모델에 대해 K-Fold Stacking 진행\n",
        "for idx, (name, model) in enumerate(models):\n",
        "    test_fold_preds = np.zeros((X_test_scaled.shape[0], kf.n_splits))\n",
        "\n",
        "    for fold, (train_idx, valid_idx) in enumerate(kf.split(X_train, y_train)):\n",
        "        X_tr, X_val = X_train[train_idx], X_train[valid_idx]\n",
        "        y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[valid_idx]\n",
        "\n",
        "        model.fit(X_tr, y_tr)\n",
        "        train_meta_features[valid_idx, idx] = model.predict_proba(X_val)[:, 1]\n",
        "        test_fold_preds[:, fold] = model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "    test_meta_features[:, idx] = test_fold_preds.mean(axis=1)\n",
        "\n",
        "# 🔥 메타 모델을 XGBoost로 변경하여 최종 학습\n",
        "meta_model = XGBClassifier(n_estimators=100, learning_rate=0.05, random_state=42)\n",
        "meta_model.fit(train_meta_features, y_train)\n",
        "\n",
        "# 최종 예측\n",
        "final_valid_pred = meta_model.predict_proba(train_meta_features)[:, 1]\n",
        "roc_auc_stacking = roc_auc_score(y_train, final_valid_pred)\n",
        "print(f\"📌 개선된 Stacking 모델 ROC-AUC: {roc_auc_stacking:.6f}\")\n",
        "\n",
        "final_test_pred = meta_model.predict_proba(test_meta_features)[:, 1]\n",
        "submission = pd.DataFrame({\"UID\": test_UID, \"채무 불이행 확률\": final_test_pred})\n",
        "submission.to_csv(\"submission_stacking.csv\", index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zsMtkvIaxDC",
        "outputId": "4a2dbde5-c063-4e68-ad79-1cc942b5680e"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📌 개선된 Stacking 모델 ROC-AUC: 0.805834\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## test에서 성능이 앙상블보다 떨어짐"
      ],
      "metadata": {
        "id": "j0FR2HsLbLLB"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ut0orItwcXpL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}