{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "BeCUXFbKfZEx"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ë”¥ëŸ¬ë‹"
      ],
      "metadata": {
        "id": "NSgj0RlNhZU8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# âœ… ë°ì´í„° ë¡œë“œ\n",
        "train_path = \"train.csv\"\n",
        "test_path = \"test.csv\"\n",
        "\n",
        "train_df = pd.read_csv(train_path)\n",
        "test_df = pd.read_csv(test_path)\n",
        "\n",
        "# âœ… ëª©í‘œ ë³€ìˆ˜ ë¶„ë¦¬\n",
        "X = train_df.drop(columns=[\"UID\", \"ì±„ë¬´ ë¶ˆì´í–‰ ì—¬ë¶€\"])\n",
        "y = train_df[\"ì±„ë¬´ ë¶ˆì´í–‰ ì—¬ë¶€\"]\n",
        "\n",
        "# í…ŒìŠ¤íŠ¸ ë°ì´í„° UID ì €ì¥\n",
        "test_UID = test_df.pop(\"UID\")\n",
        "X_test = test_df\n",
        "\n",
        "# âœ… ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ì½”ë”©\n",
        "categorical_cols = [\"ì£¼ê±° í˜•íƒœ\", \"ëŒ€ì¶œ ëª©ì \", \"ëŒ€ì¶œ ìƒí™˜ ê¸°ê°„\"]\n",
        "label_col = \"í˜„ì¬ ì§ì¥ ê·¼ì† ì—°ìˆ˜\"\n",
        "\n",
        "# OneHot Encoding (ì£¼ê±° í˜•íƒœ, ëŒ€ì¶œ ëª©ì , ëŒ€ì¶œ ìƒí™˜ ê¸°ê°„)\n",
        "encoder = OneHotEncoder(sparse_output=False, drop=\"first\")\n",
        "X_encoded = encoder.fit_transform(X[categorical_cols])\n",
        "X_test_encoded = encoder.transform(X_test[categorical_cols])\n",
        "encoded_cols = encoder.get_feature_names_out(categorical_cols)\n",
        "\n",
        "X_encoded_df = pd.DataFrame(X_encoded, columns=encoded_cols, index=X.index)\n",
        "X_test_encoded_df = pd.DataFrame(X_test_encoded, columns=encoded_cols, index=X_test.index)\n",
        "\n",
        "# Label Encoding (í˜„ì¬ ì§ì¥ ê·¼ì† ì—°ìˆ˜)\n",
        "label_encoder = LabelEncoder()\n",
        "X[label_col] = label_encoder.fit_transform(X[label_col])\n",
        "X_test[label_col] = label_encoder.transform(X_test[label_col])\n",
        "\n",
        "# âœ… ê¸°ì¡´ ë°ì´í„°ì—ì„œ ë²”ì£¼í˜• ë³€ìˆ˜ ì œê±° í›„ ê²°í•©\n",
        "X = X.drop(columns=categorical_cols).reset_index(drop=True)\n",
        "X_test = X_test.drop(columns=categorical_cols).reset_index(drop=True)\n",
        "\n",
        "X = pd.concat([X, X_encoded_df], axis=1)\n",
        "X_test = pd.concat([X_test, X_test_encoded_df], axis=1)\n",
        "\n",
        "# ë¡œê·¸ ë³€í™˜\n",
        "log_columns = [\"í˜„ì¬ ë¯¸ìƒí™˜ ì‹ ìš©ì•¡\", \"ì›” ìƒí™˜ ë¶€ì±„ì•¡\", \"í˜„ì¬ ëŒ€ì¶œ ì”ì•¡\"]\n",
        "for col in log_columns:\n",
        "    X[col] = np.log1p(X[col])\n",
        "    X_test[col] = np.log1p(X_test[col])\n",
        "\n",
        "# âœ… ë°ì´í„° ìŠ¤ì¼€ì¼ë§\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# âœ… í›ˆë ¨ ë°ì´í„° ë¶„í• \n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# âœ… MLP (Multi-Layer Perceptron) ëª¨ë¸ ì„¤ê³„\n",
        "def build_model(input_dim):\n",
        "    model = keras.Sequential([\n",
        "        layers.Dense(128, activation=\"relu\", input_shape=(input_dim,)),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dropout(0.3),\n",
        "\n",
        "        layers.Dense(64, activation=\"relu\"),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dropout(0.3),\n",
        "\n",
        "        layers.Dense(32, activation=\"relu\"),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dropout(0.3),\n",
        "\n",
        "        layers.Dense(1, activation=\"sigmoid\")  # Binary Classification\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "                  loss=\"binary_crossentropy\",\n",
        "                  metrics=[keras.metrics.AUC()])\n",
        "\n",
        "    return model\n",
        "\n",
        "# âœ… ëª¨ë¸ ìƒì„±\n",
        "model = build_model(X_train.shape[1])\n",
        "\n",
        "# âœ… ëª¨ë¸ í•™ìŠµ\n",
        "early_stopping = keras.callbacks.EarlyStopping(monitor=\"val_auc\", patience=10, restore_best_weights=True, mode=\"max\")\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_valid, y_valid),\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        "    callbacks=[early_stopping],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# âœ… ê²€ì¦ ë°ì´í„° ì„±ëŠ¥ í‰ê°€\n",
        "y_valid_pred = model.predict(X_valid).flatten()\n",
        "roc_auc = roc_auc_score(y_valid, y_valid_pred)\n",
        "print(f\"ğŸ”¥ ë”¥ëŸ¬ë‹ ëª¨ë¸ ROC-AUC: {roc_auc:.6f}\")\n",
        "\n",
        "# âœ… í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡\n",
        "y_test_pred = model.predict(X_test_scaled).flatten()\n",
        "\n",
        "# âœ… ì œì¶œ íŒŒì¼ ìƒì„±\n",
        "submission = pd.DataFrame({\"UID\": test_UID, \"ì±„ë¬´ ë¶ˆì´í–‰ í™•ë¥ \": y_test_pred})\n",
        "submission.to_csv(\"submission.csv\", index=False)\n",
        "\n",
        "print(\"âœ… ë”¥ëŸ¬ë‹ ëª¨ë¸ ì˜ˆì¸¡ ì™„ë£Œ! ê²°ê³¼ê°€ submission.csvì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vuBOAaUstoiy",
        "outputId": "2d965955-38d4-4c73-b74c-6ad53ea3a08a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 26ms/step - auc: 0.5669 - loss: 0.7910 - val_auc: 0.7143 - val_loss: 0.5813\n",
            "Epoch 2/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - auc: 0.6507 - loss: 0.6366 - val_auc: 0.7129 - val_loss: 0.5814\n",
            "Epoch 3/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - auc: 0.6863 - loss: 0.6028 - val_auc: 0.7195 - val_loss: 0.5750\n",
            "Epoch 4/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - auc: 0.6898 - loss: 0.5959 - val_auc: 0.7196 - val_loss: 0.5722\n",
            "Epoch 5/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - auc: 0.7082 - loss: 0.5833 - val_auc: 0.7246 - val_loss: 0.5693\n",
            "Epoch 6/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7013 - loss: 0.5896 - val_auc: 0.7261 - val_loss: 0.5689\n",
            "Epoch 7/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7257 - loss: 0.5652 - val_auc: 0.7284 - val_loss: 0.5661\n",
            "Epoch 8/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7271 - loss: 0.5668 - val_auc: 0.7287 - val_loss: 0.5672\n",
            "Epoch 9/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7161 - loss: 0.5705 - val_auc: 0.7286 - val_loss: 0.5662\n",
            "Epoch 10/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - auc: 0.7162 - loss: 0.5745 - val_auc: 0.7305 - val_loss: 0.5641\n",
            "Epoch 11/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - auc: 0.7287 - loss: 0.5664 - val_auc: 0.7297 - val_loss: 0.5648\n",
            "Epoch 12/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7320 - loss: 0.5607 - val_auc: 0.7307 - val_loss: 0.5641\n",
            "Epoch 13/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7324 - loss: 0.5643 - val_auc: 0.7328 - val_loss: 0.5623\n",
            "Epoch 14/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7248 - loss: 0.5646 - val_auc: 0.7321 - val_loss: 0.5637\n",
            "Epoch 15/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7384 - loss: 0.5585 - val_auc: 0.7326 - val_loss: 0.5625\n",
            "Epoch 16/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7375 - loss: 0.5639 - val_auc: 0.7295 - val_loss: 0.5648\n",
            "Epoch 17/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7401 - loss: 0.5585 - val_auc: 0.7269 - val_loss: 0.5676\n",
            "Epoch 18/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7390 - loss: 0.5540 - val_auc: 0.7289 - val_loss: 0.5662\n",
            "Epoch 19/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7437 - loss: 0.5587 - val_auc: 0.7309 - val_loss: 0.5635\n",
            "Epoch 20/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - auc: 0.7478 - loss: 0.5529 - val_auc: 0.7309 - val_loss: 0.5647\n",
            "Epoch 21/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7431 - loss: 0.5602 - val_auc: 0.7304 - val_loss: 0.5647\n",
            "Epoch 22/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7525 - loss: 0.5517 - val_auc: 0.7333 - val_loss: 0.5625\n",
            "Epoch 23/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7423 - loss: 0.5580 - val_auc: 0.7343 - val_loss: 0.5620\n",
            "Epoch 24/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7538 - loss: 0.5424 - val_auc: 0.7281 - val_loss: 0.5663\n",
            "Epoch 25/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7491 - loss: 0.5487 - val_auc: 0.7315 - val_loss: 0.5634\n",
            "Epoch 26/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7557 - loss: 0.5492 - val_auc: 0.7270 - val_loss: 0.5673\n",
            "Epoch 27/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7515 - loss: 0.5487 - val_auc: 0.7281 - val_loss: 0.5668\n",
            "Epoch 28/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7441 - loss: 0.5521 - val_auc: 0.7286 - val_loss: 0.5676\n",
            "Epoch 29/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7534 - loss: 0.5488 - val_auc: 0.7292 - val_loss: 0.5660\n",
            "Epoch 30/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - auc: 0.7442 - loss: 0.5514 - val_auc: 0.7306 - val_loss: 0.5658\n",
            "Epoch 31/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - auc: 0.7507 - loss: 0.5493 - val_auc: 0.7306 - val_loss: 0.5662\n",
            "Epoch 32/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.7655 - loss: 0.5442 - val_auc: 0.7275 - val_loss: 0.5672\n",
            "Epoch 33/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.7599 - loss: 0.5422 - val_auc: 0.7287 - val_loss: 0.5668\n",
            "\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            "ğŸ”¥ ë”¥ëŸ¬ë‹ ëª¨ë¸ ROC-AUC: 0.734086\n",
            "\u001b[1m65/65\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "âœ… ë”¥ëŸ¬ë‹ ëª¨ë¸ ì˜ˆì¸¡ ì™„ë£Œ! ê²°ê³¼ê°€ submission.csvì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aCFoCRYCx_EY"
      },
      "execution_count": 2,
      "outputs": []
    }
  ]
}